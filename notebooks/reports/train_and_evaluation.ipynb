{"cells":[{"cell_type":"markdown","metadata":{"id":"CeuirtPBI92v"},"source":["# For Colab"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Ei5gMJMyzvYZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709897671107,"user_tz":-210,"elapsed":19558,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"2e2a0dcf-ad1c-46dc-b04b-72aeaedd02cf"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCGyVNJgI92z","executionInfo":{"status":"ok","timestamp":1709897712998,"user_tz":-210,"elapsed":600,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"a26325d3-4a48-4633-c595-373ff81404c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/PythonProjects/skgnmda\n"]}],"source":["!pwd"]},{"cell_type":"code","source":["cd /content/drive/MyDrive/PythonProjects/skgnmda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_hfsSOp2BFY","executionInfo":{"status":"ok","timestamp":1709897709998,"user_tz":-210,"elapsed":394,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"387e4689-eaac-4826-f9f4-b1374df78a7f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/PythonProjects/skgnmda\n"]}]},{"cell_type":"markdown","source":["# Prerequirements"],"metadata":{"id":"BN1Q4-GPZ1RQ"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"BLTv-fDNI921","executionInfo":{"status":"ok","timestamp":1709897715780,"user_tz":-210,"elapsed":377,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"outputs":[],"source":["dataset = 'mdkg_hmdad'"]},{"cell_type":"code","source":["from tensorflow.python.client import device_lib\n","\n","print(device_lib.list_local_devices())"],"metadata":{"id":"sVj9Op1oclbW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709897721327,"user_tz":-210,"elapsed":3785,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"15f1cddc-5bc1-49f2-fa84-54ad1a2a29a4"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 14388704342630274988\n","xla_global_id: -1\n","]\n"]}]},{"cell_type":"markdown","metadata":{"id":"isSIExHAI922"},"source":["# Load Data"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"YCW06UEyI922","executionInfo":{"status":"ok","timestamp":1709897726977,"user_tz":-210,"elapsed":2293,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"outputs":[],"source":["from src.config import DISEASE_MICROBE_EXAMPLE, PROCESSED_DATA_DIR\n","from src.utils import format_filename\n","import numpy as np\n","\n","examples_file = format_filename(\n","    PROCESSED_DATA_DIR, DISEASE_MICROBE_EXAMPLE, dataset=dataset\n",")\n","examples = np.load(examples_file)"]},{"cell_type":"code","source":["examples.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aj0nHfcaoAu","executionInfo":{"status":"ok","timestamp":1709897729212,"user_tz":-210,"elapsed":369,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"f7630e74-afd8-48d6-d003-fab470118143"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(898, 3)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["examples[:3, ]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v0BFUuKFaqGU","executionInfo":{"status":"ok","timestamp":1709897730844,"user_tz":-210,"elapsed":3,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"be233bb6-7cc3-4dee-b3f1-96e6ee3278d8"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[50863, 33211,     1],\n","       [43621, 40832,     1],\n","       [33293, 47880,     1]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from src.data import MicrobeDiseaseData\n","\n","data = MicrobeDiseaseData([examples[:, :1], examples[:, 1:2]], examples[:, 2:3].reshape(-1))"],"metadata":{"id":"NpKB-ffyqoiR","executionInfo":{"status":"ok","timestamp":1709897735467,"user_tz":-210,"elapsed":1919,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"T7D_ZHkTI922","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709897740072,"user_tz":-210,"elapsed":2089,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"6d282658-3f12-4ed2-bbe3-a772d92ddee7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Logging Info - Loaded: /content/drive/MyDrive/PythonProjects/skgnmda/data_repository/processed/mdkg_hmdad_entity_vocab.pkl\n"]}],"source":["from keras import backend as K\n","from src.config import MICROBE_SIMILARITY_FILE, DISEASE_SIMILARITY_FILE, PROCESSED_DATA_DIR, ENTITY_VOCAB_TEMPLATE\n","import pandas as pd\n","from src.utils import pickle_load\n","import tensorflow as tf\n","\n","microbe_similarity_df = pd.read_csv(MICROBE_SIMILARITY_FILE, index_col=0)\n","disease_similarity_df = pd.read_csv(DISEASE_SIMILARITY_FILE, index_col=0)\n","\n","entity_vocab_size = len(\n","    pickle_load(\n","        format_filename(PROCESSED_DATA_DIR, ENTITY_VOCAB_TEMPLATE, dataset=dataset)\n","    )\n",")\n","\n","microbe_similarity_matrix = np.zeros((entity_vocab_size, microbe_similarity_df.shape[1]), dtype=\"float64\")\n","disease_similarity_matrix = np.zeros((entity_vocab_size, disease_similarity_df.shape[1]), dtype=\"float64\")\n","\n","for i, row in microbe_similarity_df.iterrows():\n","    for j in range(len(row)):\n","        microbe_similarity_matrix[i][j] = row[j]\n","\n","for i, row in disease_similarity_df.iterrows():\n","    for j in range(len(row)):\n","        disease_similarity_matrix[i][j] = row[j]\n","\n","microbe_similarity_matrix = tf.Variable(microbe_similarity_matrix,\n","                                        name='pre_term_microbe_embedding',\n","                                        dtype='float32',\n","                                        trainable=False)\n","disease_similarity_matrix = tf.Variable(disease_similarity_matrix,\n","                                        name='pre_term_disease_embedding',\n","                                        dtype='float32',\n","                                        trainable=False)"]},{"cell_type":"code","source":["def get_first_term_embedding(x):\n","    microbe_pre_embed = K.gather(microbe_similarity_matrix, K.cast(x, dtype='int64'))\n","    return microbe_pre_embed\n","\n","\n","def get_second_term_embedding(x):\n","    disease_pre_embed = K.gather(disease_similarity_matrix, K.cast(x, dtype='int64'))\n","    return disease_pre_embed"],"metadata":{"id":"Bsbu7LlD6iVt","executionInfo":{"status":"ok","timestamp":1709897741967,"user_tz":-210,"elapsed":2,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Configure Model"],"metadata":{"id":"IvFOWu22ihTb"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"tXF2E-9EI921","executionInfo":{"status":"ok","timestamp":1709897744570,"user_tz":-210,"elapsed":410,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"outputs":[],"source":["from src.config import KGCNModelConfig\n","\n","kgcn_config = KGCNModelConfig()\n","\n","kgcn_config.model_name = 'Previous 1'\n","kgcn_config.embed_dim = 32\n","kgcn_config.neighbor_sample_size = 8\n","kgcn_config.n_depth = 2\n","kgcn_config.l2_weight = 0.01\n","kgcn_config.aggregator_type = 'sum'"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2NaSx0nI921","executionInfo":{"status":"ok","timestamp":1709897749164,"user_tz":-210,"elapsed":349,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"7acfc725-06f0-4ed6-e098-e298c441e124"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'model_name': 'Previous 1',\n"," 'embed_dim': 32,\n"," 'neighbor_sample_size': 8,\n"," 'n_depth': 2,\n"," 'l2_weight': 0.01,\n"," 'aggregator_type': 'sum'}"]},"metadata":{},"execution_count":15}],"source":["kgcn_config.get_summary()"]},{"cell_type":"markdown","source":["# Configure Data"],"metadata":{"id":"j9-8KPlNiqmM"}},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UE7vhrTaI921","executionInfo":{"status":"ok","timestamp":1709897755334,"user_tz":-210,"elapsed":939,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"e79ec67e-f2b0-437b-a3a5-274283e83572"},"outputs":[{"output_type":"stream","name":"stdout","text":["Logging Info - Loaded: /content/drive/MyDrive/PythonProjects/skgnmda/data_repository/processed/mdkg_hmdad_entity_vocab.pkl\n","Logging Info - Loaded: /content/drive/MyDrive/PythonProjects/skgnmda/data_repository/processed/mdkg_hmdad_relation_vocab.pkl\n"]}],"source":["from src.config import DataConfig, PROCESSED_DATA_DIR, ENTITY_VOCAB_TEMPLATE, \\\n","    RELATION_VOCAB_TEMPLATE, ADJ_ENTITY_TEMPLATE, ADJ_RELATION_TEMPLATE\n","from src.utils import pickle_load, format_filename\n","import numpy as np\n","\n","data_config = DataConfig()\n","\n","data_config.entity_vocab_size = len(\n","    pickle_load(\n","        format_filename(PROCESSED_DATA_DIR, ENTITY_VOCAB_TEMPLATE, dataset=dataset)\n","    )\n",")  # the size of entity_vocab\n","\n","data_config.relation_vocab_size = len(\n","    pickle_load(\n","        format_filename(\n","            PROCESSED_DATA_DIR, RELATION_VOCAB_TEMPLATE, dataset=dataset\n","        )\n","    )\n",")  # the size of relation_vocab\n","\n","data_config.adj_entity = np.load(\n","    format_filename(PROCESSED_DATA_DIR, ADJ_ENTITY_TEMPLATE, dataset=dataset)\n",")  # load adj_entity matrix\n","\n","data_config.adj_relation = np.load(\n","    format_filename(PROCESSED_DATA_DIR, ADJ_RELATION_TEMPLATE, dataset=dataset)\n",")  # load adj_relation matrix\n"]},{"cell_type":"code","source":["data_config.get_summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l_CyZBzHgyaq","executionInfo":{"status":"ok","timestamp":1709897757715,"user_tz":-210,"elapsed":404,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"60092fb0-2fde-44dc-9e93-74b74c951d3f"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'entity_vocab_size': 66911, 'relation_vocab_size': 39}"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"b43tnuG-I920"},"source":["# Bulid Model"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"n4DpyKjxI922","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709897765867,"user_tz":-210,"elapsed":4109,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"0f656bce-b924-4998-bf22-b81017fcd6ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='lambda_1/Squeeze:0', description=\"created by layer 'lambda_1'\")\n"]}],"source":["from src.models.graph_models import PairKGCN\n","\n","model = PairKGCN(kgcn_config=kgcn_config,\n","                 data_config=data_config)"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"WI58H70bPT3o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709897769153,"user_tz":-210,"elapsed":589,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"b35abdca-b95e-4f5c-cdd2-8e1c0123c004"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," second_input (InputLayer)   [(None, 1)]                  0         []                            \n","                                                                                                  \n"," receptive_filed_for_second  [(None, 1),                  0         ['second_input[0][0]']        \n"," _ent (Lambda)                (None, 8),                                                          \n","                              (None, 64)]                                                         \n","                                                                                                  \n"," receptive_filed_for_second  [(None, 8),                  0         ['second_input[0][0]']        \n"," _rel (Lambda)                (None, 64)]                                                         \n","                                                                                                  \n"," entity_embedding (Embeddin  multiple                     2141152   ['receptive_filed_for_microbe_\n"," g)                                                                 ent[0][0]',                   \n","                                                                     'receptive_filed_for_microbe_\n","                                                                    ent[0][1]',                   \n","                                                                     'receptive_filed_for_microbe_\n","                                                                    ent[0][2]',                   \n","                                                                     'receptive_filed_for_second_e\n","                                                                    nt[0][0]',                    \n","                                                                     'receptive_filed_for_second_e\n","                                                                    nt[0][1]',                    \n","                                                                     'receptive_filed_for_second_e\n","                                                                    nt[0][2]']                    \n","                                                                                                  \n"," second_embedding (Embeddin  (None, 1, 32)                2141152   ['second_input[0][0]']        \n"," g)                                                                                               \n","                                                                                                  \n"," relation_embedding (Embedd  multiple                     1248      ['receptive_filed_for_microbe_\n"," ing)                                                               rel[0][0]',                   \n","                                                                     'receptive_filed_for_microbe_\n","                                                                    rel[0][1]',                   \n","                                                                     'receptive_filed_for_second_r\n","                                                                    el[0][0]',                    \n","                                                                     'receptive_filed_for_second_r\n","                                                                    el[0][1]']                    \n","                                                                                                  \n"," first_input (InputLayer)    [(None, 1)]                  0         []                            \n","                                                                                                  \n"," neigh_embedding (Lambda)    (None, None, 32)             0         ['first_embedding[0][0]',     \n","                                                                     'relation_embedding[0][0]',  \n","                                                                     'entity_embedding[1][0]',    \n","                                                                     'first_embedding[0][0]',     \n","                                                                     'relation_embedding[1][0]',  \n","                                                                     'entity_embedding[2][0]',    \n","                                                                     'first_embedding[0][0]',     \n","                                                                     'relation_embedding[0][0]',  \n","                                                                     'first_aggregator_1[1][0]',  \n","                                                                     'second_embedding[0][0]',    \n","                                                                     'relation_embedding[2][0]',  \n","                                                                     'entity_embedding[4][0]',    \n","                                                                     'second_embedding[0][0]',    \n","                                                                     'relation_embedding[3][0]',  \n","                                                                     'entity_embedding[5][0]',    \n","                                                                     'second_embedding[0][0]',    \n","                                                                     'relation_embedding[2][0]',  \n","                                                                     'aggregator_1[1][0]']        \n","                                                                                                  \n"," receptive_filed_for_microb  [(None, 1),                  0         ['first_input[0][0]']         \n"," e_ent (Lambda)               (None, 8),                                                          \n","                              (None, 64)]                                                         \n","                                                                                                  \n"," receptive_filed_for_microb  [(None, 8),                  0         ['first_input[0][0]']         \n"," e_rel (Lambda)               (None, 64)]                                                         \n","                                                                                                  \n"," aggregator_1 (SumAggregato  multiple                     1056      ['entity_embedding[3][0]',    \n"," r)                                                                  'neigh_embedding[3][0]',     \n","                                                                     'entity_embedding[4][0]',    \n","                                                                     'neigh_embedding[4][0]']     \n","                                                                                                  \n"," first_embedding (Embedding  (None, 1, 32)                2141152   ['first_input[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," first_aggregator_1 (SumAgg  multiple                     1056      ['entity_embedding[0][0]',    \n"," regator)                                                            'neigh_embedding[0][0]',     \n","                                                                     'entity_embedding[1][0]',    \n","                                                                     'neigh_embedding[1][0]']     \n","                                                                                                  \n"," aggregator_2 (SumAggregato  (None, None, 32)             1056      ['aggregator_1[0][0]',        \n"," r)                                                                  'neigh_embedding[5][0]']     \n","                                                                                                  \n"," first_aggregator_2 (SumAgg  (None, None, 32)             1056      ['first_aggregator_1[0][0]',  \n"," regator)                                                            'neigh_embedding[2][0]']     \n","                                                                                                  \n"," lambda_1 (Lambda)           (None, 32)                   0         ['aggregator_2[0][0]']        \n","                                                                                                  \n"," lambda (Lambda)             (None, 32)                   0         ['first_aggregator_2[0][0]']  \n","                                                                                                  \n"," pair_score (PairScore)      (None, 1)                    2080      ['lambda_1[0][0]',            \n","                                                                     'lambda[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 6431008 (24.53 MB)\n","Trainable params: 6431008 (24.53 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# Configure Optimizer"],"metadata":{"id":"E519kO_IixLi"}},{"cell_type":"code","source":["from base.config import OptimizerConfig\n","from src.config import MODEL_SAVED_DIR"],"metadata":{"id":"LgCI-LDmi1N5","executionInfo":{"status":"ok","timestamp":1709897775352,"user_tz":-210,"elapsed":335,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["optimizer_config = OptimizerConfig()\n","optimizer_config.optimizer = 'adam'\n","optimizer_config.lr = 1e-3\n","optimizer_config.batch_size = 32\n","optimizer_config.n_epoch = 50\n","optimizer_config.checkpoint_dir = MODEL_SAVED_DIR\n","optimizer_config.callbacks_to_add = []"],"metadata":{"id":"gfUkUFNfqjhZ","executionInfo":{"status":"ok","timestamp":1709897776500,"user_tz":-210,"elapsed":557,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UMwakPsuI922"},"source":["# Train Model"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"FayntTuDI922","executionInfo":{"status":"ok","timestamp":1709897782785,"user_tz":-210,"elapsed":1001,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"outputs":[],"source":["from src.optimization.optimization import KGCNTrainer"]},{"cell_type":"code","source":["trainer = KGCNTrainer()\n","result = trainer.train(model, data, optimizer_config, [])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vNj4SbUxMhFB","outputId":"55ab9cc4-bd49-4c72-f254-1eb8db682ce0","executionInfo":{"status":"ok","timestamp":1709897942667,"user_tz":-210,"elapsed":147297,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","29/29 [==============================] - 7s 108ms/step - loss: 3.0151 - acc: 0.5000 - mae: 0.5067 - auc: 0.5111\n","Epoch 2/50\n","29/29 [==============================] - 3s 100ms/step - loss: 2.2266 - acc: 0.5000 - mae: 0.5304 - auc: 0.7269\n","Epoch 3/50\n","29/29 [==============================] - 3s 88ms/step - loss: 1.7346 - acc: 0.6548 - mae: 0.9460 - auc: 0.8012\n","Epoch 4/50\n","29/29 [==============================] - 3s 88ms/step - loss: 1.3874 - acc: 0.7973 - mae: 1.6457 - auc: 0.8373\n","Epoch 5/50\n","29/29 [==============================] - 3s 90ms/step - loss: 1.1705 - acc: 0.7962 - mae: 1.5339 - auc: 0.8347\n","Epoch 6/50\n","29/29 [==============================] - 3s 106ms/step - loss: 1.0104 - acc: 0.7962 - mae: 1.4865 - auc: 0.8362\n","Epoch 7/50\n","29/29 [==============================] - 3s 106ms/step - loss: 0.8917 - acc: 0.7996 - mae: 1.6896 - auc: 0.8337\n","Epoch 8/50\n","29/29 [==============================] - 3s 87ms/step - loss: 0.8040 - acc: 0.7806 - mae: 1.4208 - auc: 0.8340\n","Epoch 9/50\n","29/29 [==============================] - 3s 88ms/step - loss: 0.7321 - acc: 0.7929 - mae: 1.6381 - auc: 0.8382\n","Epoch 10/50\n","29/29 [==============================] - 2s 86ms/step - loss: 0.6771 - acc: 0.7996 - mae: 1.6874 - auc: 0.8355\n","Epoch 11/50\n","29/29 [==============================] - 3s 96ms/step - loss: 0.6344 - acc: 0.7962 - mae: 1.5230 - auc: 0.8389\n","Epoch 12/50\n","29/29 [==============================] - 3s 113ms/step - loss: 0.6043 - acc: 0.7951 - mae: 1.6014 - auc: 0.8395\n","Epoch 13/50\n","29/29 [==============================] - 3s 87ms/step - loss: 0.5791 - acc: 0.7984 - mae: 1.5858 - auc: 0.8367\n","Epoch 14/50\n","29/29 [==============================] - 3s 88ms/step - loss: 0.5711 - acc: 0.7918 - mae: 1.6123 - auc: 0.8297\n","Epoch 15/50\n","29/29 [==============================] - 3s 86ms/step - loss: 0.5444 - acc: 0.8029 - mae: 1.8598 - auc: 0.8341\n","Epoch 16/50\n","29/29 [==============================] - 3s 92ms/step - loss: 0.5439 - acc: 0.7962 - mae: 1.6007 - auc: 0.8243\n","Epoch 17/50\n","29/29 [==============================] - 3s 111ms/step - loss: 0.5235 - acc: 0.7973 - mae: 1.7828 - auc: 0.8283\n","Epoch 18/50\n","29/29 [==============================] - 3s 90ms/step - loss: 0.5195 - acc: 0.7962 - mae: 1.6167 - auc: 0.8401\n","Epoch 19/50\n","29/29 [==============================] - 3s 87ms/step - loss: 0.5104 - acc: 0.8040 - mae: 1.7181 - auc: 0.8388\n","Epoch 20/50\n","29/29 [==============================] - 3s 87ms/step - loss: 0.5024 - acc: 0.7996 - mae: 1.6248 - auc: 0.8432\n","Epoch 21/50\n","29/29 [==============================] - 3s 89ms/step - loss: 0.4959 - acc: 0.8018 - mae: 1.7819 - auc: 0.8422\n","Epoch 22/50\n","29/29 [==============================] - 3s 116ms/step - loss: 0.4882 - acc: 0.8018 - mae: 1.7452 - auc: 0.8395\n","Epoch 23/50\n","29/29 [==============================] - 3s 95ms/step - loss: 0.4883 - acc: 0.8107 - mae: 1.6849 - auc: 0.8703\n","Epoch 24/50\n","29/29 [==============================] - 3s 87ms/step - loss: 0.4799 - acc: 0.8018 - mae: 1.8781 - auc: 0.8592\n","Epoch 25/50\n","29/29 [==============================] - 3s 88ms/step - loss: 0.4742 - acc: 0.8051 - mae: 1.8155 - auc: 0.8666\n","Epoch 26/50\n","29/29 [==============================] - 3s 88ms/step - loss: 0.4687 - acc: 0.8107 - mae: 1.8926 - auc: 0.8719\n","Epoch 27/50\n","29/29 [==============================] - 3s 106ms/step - loss: 0.4636 - acc: 0.8207 - mae: 1.8643 - auc: 0.8839\n","Epoch 28/50\n","29/29 [==============================] - 3s 101ms/step - loss: 0.4588 - acc: 0.8263 - mae: 1.9228 - auc: 0.8919\n","Epoch 29/50\n","29/29 [==============================] - 3s 89ms/step - loss: 0.4580 - acc: 0.8252 - mae: 1.8346 - auc: 0.8853\n","Epoch 30/50\n","29/29 [==============================] - 3s 88ms/step - loss: 0.4539 - acc: 0.8352 - mae: 2.0063 - auc: 0.8945\n","Epoch 31/50\n","29/29 [==============================] - 3s 114ms/step - loss: 0.4488 - acc: 0.8408 - mae: 1.9124 - auc: 0.9124\n","Epoch 32/50\n","29/29 [==============================] - 4s 128ms/step - loss: 0.4458 - acc: 0.8463 - mae: 2.0635 - auc: 0.9078\n","Epoch 33/50\n","29/29 [==============================] - 3s 101ms/step - loss: 0.4450 - acc: 0.8341 - mae: 2.0948 - auc: 0.9047\n","Epoch 34/50\n","29/29 [==============================] - 3s 87ms/step - loss: 0.4558 - acc: 0.8519 - mae: 1.9913 - auc: 0.8985\n","Epoch 35/50\n","29/29 [==============================] - 3s 88ms/step - loss: 0.4417 - acc: 0.8764 - mae: 2.1272 - auc: 0.9117\n","Epoch 36/50\n","29/29 [==============================] - 3s 89ms/step - loss: 0.4341 - acc: 0.8686 - mae: 2.0486 - auc: 0.9127\n","Epoch 37/50\n","29/29 [==============================] - 3s 108ms/step - loss: 0.4296 - acc: 0.8731 - mae: 2.0971 - auc: 0.9188\n","Epoch 38/50\n","29/29 [==============================] - 3s 104ms/step - loss: 0.4284 - acc: 0.8708 - mae: 2.1376 - auc: 0.9110\n","Epoch 39/50\n","29/29 [==============================] - 3s 86ms/step - loss: 0.4351 - acc: 0.8764 - mae: 2.1975 - auc: 0.9098\n","Epoch 40/50\n","29/29 [==============================] - 2s 86ms/step - loss: 0.4265 - acc: 0.8775 - mae: 2.1280 - auc: 0.9211\n","Epoch 41/50\n","29/29 [==============================] - 3s 98ms/step - loss: 0.4304 - acc: 0.8764 - mae: 2.2257 - auc: 0.9189\n","Epoch 42/50\n","29/29 [==============================] - 3s 106ms/step - loss: 0.4256 - acc: 0.8719 - mae: 2.3090 - auc: 0.9161\n","Epoch 43/50\n","29/29 [==============================] - 3s 105ms/step - loss: 0.4194 - acc: 0.8775 - mae: 2.1679 - auc: 0.9206\n","Epoch 44/50\n","29/29 [==============================] - 2s 86ms/step - loss: 0.4280 - acc: 0.8586 - mae: 2.3610 - auc: 0.9092\n","Epoch 45/50\n","29/29 [==============================] - 3s 88ms/step - loss: 0.4226 - acc: 0.8808 - mae: 2.2103 - auc: 0.9276\n","Epoch 46/50\n","29/29 [==============================] - 3s 88ms/step - loss: 0.4140 - acc: 0.8864 - mae: 2.3444 - auc: 0.9198\n","Epoch 47/50\n","29/29 [==============================] - 3s 96ms/step - loss: 0.4117 - acc: 0.8898 - mae: 2.2242 - auc: 0.9267\n","Epoch 48/50\n","29/29 [==============================] - 3s 115ms/step - loss: 0.4116 - acc: 0.8953 - mae: 2.3071 - auc: 0.9204\n","Epoch 49/50\n","29/29 [==============================] - 3s 89ms/step - loss: 0.4198 - acc: 0.8875 - mae: 2.3819 - auc: 0.9207\n","Epoch 50/50\n","29/29 [==============================] - 3s 91ms/step - loss: 0.4098 - acc: 0.8987 - mae: 2.3579 - auc: 0.9258\n","Logging Info - Training time: 00:02:25\n","29/29 [==============================] - 1s 3ms/step\n"]}]},{"cell_type":"code","source":["result.get_result()"],"metadata":{"id":"m8BAt8b08wcx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709898734443,"user_tz":-210,"elapsed":427,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"26873401-bade-4e36-f4d1-f3da01c7dec1"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'AUC': 0.9669098863596907,\n"," 'ACC': 0.8830734966592427,\n"," 'F1 Score': 0.8757396449704142,\n"," 'AUPR': 0.9551894831429586}"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"VtrgAePBI922"},"source":["# Cross Validation"]},{"cell_type":"code","source":["from src.data import MicrobeDiseaseTrainTestSplit\n","\n","train_test_spliter = MicrobeDiseaseTrainTestSplit(examples=examples,\n","                                                  with_gaussian_similarity=True)"],"metadata":{"id":"x6ATxSAjrR4z","executionInfo":{"status":"ok","timestamp":1709898741541,"user_tz":-210,"elapsed":382,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["from src.optimization.optimization import KGCNTrainer, KGCNTester\n","from src.models.graph_models import PairKGCNFactory\n","\n","trainer = KGCNTrainer()\n","tester = KGCNTester()\n","factory = PairKGCNFactory(kgcn_config,\n","                          data_config,\n","                          first_term_size=291,  #291\n","                          second_term_size=39)  #39"],"metadata":{"id":"IB5qlDtxdq3B","executionInfo":{"status":"ok","timestamp":1709898744254,"user_tz":-210,"elapsed":408,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["from base.optimization import cross_validation\n","\n","cross_validation(k=5,\n","                 data_size=len(examples),\n","                 train_test_spliter=train_test_spliter,\n","                 model_factory=factory,\n","                 trainer=trainer,\n","                 tester=tester,\n","                 optimization_config=optimizer_config)"],"metadata":{"id":"81iQGUxCc66a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709899488345,"user_tz":-210,"elapsed":741722,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"3703bec7-0ece-42b0-afea-20812861489a"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Logging Info - Fold 1 >>>>>>>>>>>>>>\n","\n","test_indices: [60, 761, 57, 392, 248, 779, 21, 431, 534, 90, 280, 241, 346, 552, 818, 81, 332, 745, 434, 778, 161, 37, 484, 593, 376, 763, 314, 605, 7, 370, 676, 213, 400, 237, 306, 330, 138, 44, 569, 98, 497, 20, 182, 447, 120, 542, 742, 626, 720, 118, 167, 566, 653, 724, 522, 523, 322, 114, 710, 638, 505, 609, 184, 576, 290, 718, 380, 147, 283, 25, 345, 639, 652, 851, 517, 32, 405, 168, 13, 868, 895, 830, 374, 845, 728, 268, 102, 389, 748, 515, 344, 737, 631, 881, 775, 425, 46, 4, 140, 341, 71, 637, 256, 224, 511, 632, 689, 893, 877, 562, 402, 105, 730, 793, 478, 379, 356, 412, 874, 564, 791, 244, 87, 767, 870, 599, 139, 654, 747, 72, 734, 879, 660, 38, 776, 433, 641, 124, 633, 99, 132, 440, 189, 894, 570, 469, 262, 122, 123, 69, 350, 453, 712, 528, 640, 665, 499, 790, 766, 255, 174, 325, 305, 886, 136, 485, 636, 764, 557, 835, 130, 855, 247, 159, 483, 340, 259, 642, 427]\n","train_indices: [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 39, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 88, 89, 91, 92, 93, 94, 95, 96, 97, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 119, 121, 125, 126, 127, 128, 129, 131, 133, 134, 135, 137, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 242, 243, 245, 246, 249, 250, 251, 252, 253, 254, 257, 258, 260, 261, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 284, 285, 286, 287, 288, 289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 311, 312, 313, 315, 316, 317, 318, 319, 320, 321, 323, 324, 326, 327, 328, 329, 331, 333, 334, 335, 336, 337, 338, 339, 342, 343, 347, 348, 349, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 375, 377, 378, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 393, 394, 395, 396, 397, 398, 399, 401, 403, 404, 406, 407, 408, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 426, 428, 429, 430, 432, 435, 436, 437, 438, 439, 441, 442, 443, 444, 445, 446, 448, 449, 450, 451, 452, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 481, 482, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 504, 506, 507, 508, 509, 510, 512, 513, 514, 516, 518, 519, 520, 521, 524, 525, 526, 527, 529, 530, 531, 532, 533, 535, 536, 537, 538, 539, 540, 541, 543, 544, 545, 546, 547, 548, 549, 550, 551, 553, 554, 555, 556, 558, 559, 560, 561, 563, 565, 567, 568, 571, 572, 573, 574, 575, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 594, 595, 596, 597, 598, 600, 601, 602, 603, 604, 606, 607, 608, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 627, 628, 629, 630, 634, 635, 643, 644, 645, 646, 647, 648, 649, 650, 651, 655, 656, 657, 658, 659, 661, 662, 663, 664, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 711, 713, 714, 715, 716, 717, 719, 721, 722, 723, 725, 726, 727, 729, 731, 732, 733, 735, 736, 738, 739, 740, 741, 743, 744, 746, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 762, 765, 768, 769, 770, 771, 772, 773, 774, 777, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 792, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 834, 836, 837, 838, 839, 840, 841, 842, 843, 844, 846, 847, 848, 849, 850, 852, 853, 854, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 869, 871, 872, 873, 875, 876, 878, 880, 882, 883, 884, 885, 887, 888, 889, 890, 891, 892, 896, 897]\n","\n","first_term2id= {64642: 0, 1667: 1, 50436: 2, 48777: 3, 10506: 4, 33293: 5, 654: 6, 30861: 7, 11153: 8, 64149: 9, 61336: 10, 63129: 11, 13213: 12, 55164: 13, 40873: 14, 34347: 15, 50863: 16, 59444: 17, 22068: 18, 3127: 19, 44991: 20, 66623: 21, 4928: 22, 25026: 23, 7877: 24, 200: 25, 44112: 26, 31069: 27, 54370: 28, 20066: 29, 43621: 30, 66282: 31, 43372: 32, 28016: 33, 12403: 34, 45301: 35, 37496: 36, 9724: 37, 13565: 38} second_term2id= {24065: 0, 19458: 1, 40449: 2, 30212: 3, 12808: 4, 50698: 5, 20492: 6, 46605: 7, 5135: 8, 37392: 9, 42514: 10, 20153: 11, 12824: 12, 37400: 13, 8218: 14, 1049: 15, 30750: 16, 48672: 17, 56353: 18, 52770: 19, 31268: 20, 46117: 21, 10276: 22, 59432: 23, 57903: 24, 2097: 25, 24627: 26, 29241: 27, 50234: 28, 19514: 29, 9788: 30, 14909: 31, 8766: 32, 60987: 33, 64571: 34, 35905: 35, 27202: 36, 26183: 37, 4683: 38, 44108: 39, 33867: 40, 7246: 41, 42577: 42, 61523: 43, 3157: 44, 12374: 45, 3669: 46, 5718: 47, 6745: 48, 64598: 49, 51285: 50, 25176: 51, 35933: 52, 54366: 53, 56416: 54, 35937: 55, 59489: 56, 4707: 57, 4193: 58, 37477: 59, 29281: 60, 35941: 61, 6245: 62, 55403: 63, 18028: 64, 57454: 65, 63599: 66, 54894: 67, 29807: 68, 42610: 69, 62073: 70, 10873: 71, 3195: 72, 46716: 73, 45697: 74, 4739: 75, 47235: 76, 11907: 77, 64132: 78, 41608: 79, 25737: 80, 29322: 81, 65679: 82, 41105: 83, 35986: 84, 38545: 85, 54932: 86, 148: 87, 20627: 88, 45720: 89, 32921: 90, 4251: 91, 53920: 92, 58532: 93, 26788: 94, 15014: 95, 60583: 96, 15528: 97, 46252: 98, 19630: 99, 45746: 100, 179: 101, 47287: 102, 59577: 103, 60601: 104, 43707: 105, 46268: 106, 36028: 107, 15547: 108, 12991: 109, 59584: 110, 52416: 111, 23739: 112, 35015: 113, 13000: 114, 57545: 115, 27335: 116, 25804: 117, 1743: 118, 5846: 119, 45273: 120, 9949: 121, 5344: 122, 63715: 123, 19172: 124, 38632: 125, 1773: 126, 29422: 127, 57582: 128, 48368: 129, 61681: 130, 20724: 131, 35575: 132, 32506: 133, 30970: 134, 16122: 135, 12541: 136, 25341: 137, 56575: 138, 34048: 139, 11010: 140, 7427: 141, 15620: 142, 45317: 143, 35590: 144, 28933: 145, 47880: 146, 34574: 147, 61711: 148, 23823: 149, 57617: 150, 20754: 151, 23314: 152, 5396: 153, 58642: 154, 65813: 155, 28944: 156, 23832: 157, 65819: 158, 44316: 159, 27935: 160, 8480: 161, 25376: 162, 19744: 163, 6432: 164, 55588: 165, 51493: 166, 1823: 167, 40740: 168, 14120: 169, 8488: 170, 56106: 171, 12583: 172, 32044: 173, 53038: 174, 64304: 175, 62257: 176, 34610: 177, 5427: 178, 51508: 179, 6454: 180, 15670: 181, 39226: 182, 63804: 183, 10559: 184, 60226: 185, 22850: 186, 16707: 187, 10565: 188, 35142: 189, 49992: 190, 13641: 191, 18765: 192, 6993: 193, 54098: 194, 7506: 195, 59219: 196, 7507: 197, 11601: 198, 32087: 199, 25943: 200, 7516: 201, 65885: 202, 32606: 203, 40800: 204, 31584: 205, 57696: 206, 60261: 207, 30566: 208, 39272: 209, 50024: 210, 63336: 211, 52077: 212, 878: 213, 13682: 214, 26995: 215, 25460: 216, 27509: 217, 19319: 218, 32631: 219, 4986: 220, 32635: 221, 3965: 222, 40832: 223, 59776: 224, 32642: 225, 5508: 226, 57221: 227, 20358: 228, 7051: 229, 48011: 230, 56210: 231, 19860: 232, 56727: 233, 53656: 234, 926: 235, 49054: 236, 29598: 237, 48031: 238, 53155: 239, 55203: 240, 33701: 241, 18341: 242, 39335: 243, 6056: 244, 15268: 245, 32170: 246, 61356: 247, 431: 248, 8113: 249, 33201: 250, 34740: 251, 7093: 252, 54199: 253, 28601: 254, 25018: 255, 33211: 256, 25020: 257, 41916: 258, 30654: 259, 11709: 260, 57280: 261, 12223: 262, 53186: 263, 10691: 264, 26565: 265, 34758: 266, 9670: 267, 7114: 268, 34763: 269, 3530: 270, 14286: 271, 51153: 272, 22484: 273, 16341: 274, 54235: 275, 41953: 276, 32254: 277, 56808: 278, 29163: 279, 4589: 280, 46062: 281, 63471: 282, 53233: 283, 21490: 284, 18423: 285, 23544: 286, 65017: 287, 6651: 288, 33790: 289, 23039: 290}\n","KerasTensor(type_spec=TensorSpec(shape=(None, 71), dtype=tf.float32, name=None), name='lambda_5/concat:0', description=\"created by layer 'lambda_5'\")\n","Epoch 1/50\n","23/23 [==============================] - 6s 107ms/step - loss: 3.1267 - acc: 0.7038 - mae: 2.1904 - auc_1: 0.8386\n","Epoch 2/50\n","23/23 [==============================] - 3s 124ms/step - loss: 2.2478 - acc: 0.8567 - mae: 2.5968 - auc_1: 0.9085\n","Epoch 3/50\n","23/23 [==============================] - 2s 91ms/step - loss: 1.8226 - acc: 0.8887 - mae: 2.7972 - auc_1: 0.9176\n","Epoch 4/50\n","23/23 [==============================] - 2s 92ms/step - loss: 1.5006 - acc: 0.9040 - mae: 2.8165 - auc_1: 0.9293\n","Epoch 5/50\n","23/23 [==============================] - 2s 92ms/step - loss: 1.2472 - acc: 0.9013 - mae: 2.8555 - auc_1: 0.9303\n","Epoch 6/50\n","23/23 [==============================] - 2s 88ms/step - loss: 1.0475 - acc: 0.9110 - mae: 2.9329 - auc_1: 0.9352\n","Epoch 7/50\n","23/23 [==============================] - 2s 93ms/step - loss: 0.8882 - acc: 0.9054 - mae: 3.1246 - auc_1: 0.9346\n","Epoch 8/50\n","23/23 [==============================] - 3s 122ms/step - loss: 0.7734 - acc: 0.8999 - mae: 3.4364 - auc_1: 0.9418\n","Epoch 9/50\n","23/23 [==============================] - 2s 100ms/step - loss: 0.6747 - acc: 0.9054 - mae: 3.4174 - auc_1: 0.9271\n","Epoch 10/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.5829 - acc: 0.9040 - mae: 3.5669 - auc_1: 0.9229\n","Epoch 11/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.5270 - acc: 0.9096 - mae: 3.3974 - auc_1: 0.9343\n","Epoch 12/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.4669 - acc: 0.9040 - mae: 3.0883 - auc_1: 0.9328\n","Epoch 13/50\n","23/23 [==============================] - 2s 95ms/step - loss: 0.4229 - acc: 0.9096 - mae: 3.3818 - auc_1: 0.9364\n","Epoch 14/50\n","23/23 [==============================] - 3s 116ms/step - loss: 0.4000 - acc: 0.9110 - mae: 3.5392 - auc_1: 0.9347\n","Epoch 15/50\n","23/23 [==============================] - 2s 103ms/step - loss: 0.3686 - acc: 0.9096 - mae: 3.3849 - auc_1: 0.9371\n","Epoch 16/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.3431 - acc: 0.9054 - mae: 3.2766 - auc_1: 0.9352\n","Epoch 17/50\n","23/23 [==============================] - 2s 88ms/step - loss: 0.3253 - acc: 0.9082 - mae: 3.5224 - auc_1: 0.9345\n","Epoch 18/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.3136 - acc: 0.9110 - mae: 3.4050 - auc_1: 0.9362\n","Epoch 19/50\n","23/23 [==============================] - 2s 91ms/step - loss: 0.3010 - acc: 0.9054 - mae: 3.2519 - auc_1: 0.9419\n","Epoch 20/50\n","23/23 [==============================] - 2s 108ms/step - loss: 0.2898 - acc: 0.9124 - mae: 3.4959 - auc_1: 0.9324\n","Epoch 21/50\n","23/23 [==============================] - 3s 126ms/step - loss: 0.2795 - acc: 0.9110 - mae: 3.3476 - auc_1: 0.9375\n","Epoch 22/50\n","23/23 [==============================] - 3s 142ms/step - loss: 0.2793 - acc: 0.9082 - mae: 3.5749 - auc_1: 0.9356\n","Epoch 23/50\n","23/23 [==============================] - 3s 130ms/step - loss: 0.2691 - acc: 0.9040 - mae: 3.4015 - auc_1: 0.9340\n","Epoch 24/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.2659 - acc: 0.9082 - mae: 3.6138 - auc_1: 0.9331\n","Epoch 25/50\n","23/23 [==============================] - 2s 107ms/step - loss: 0.2639 - acc: 0.9124 - mae: 3.5697 - auc_1: 0.9391\n","Epoch 26/50\n","23/23 [==============================] - 3s 118ms/step - loss: 0.2564 - acc: 0.9096 - mae: 3.4184 - auc_1: 0.9361\n","Epoch 27/50\n","23/23 [==============================] - 2s 93ms/step - loss: 0.2581 - acc: 0.9096 - mae: 3.4524 - auc_1: 0.9346\n","Epoch 28/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.2524 - acc: 0.9152 - mae: 3.4426 - auc_1: 0.9398\n","Epoch 29/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.2537 - acc: 0.9110 - mae: 3.5948 - auc_1: 0.9354\n","Epoch 30/50\n","23/23 [==============================] - 2s 90ms/step - loss: 0.2564 - acc: 0.9082 - mae: 3.4696 - auc_1: 0.9303\n","Epoch 31/50\n","23/23 [==============================] - 2s 100ms/step - loss: 0.2492 - acc: 0.9124 - mae: 3.6949 - auc_1: 0.9319\n","Epoch 32/50\n","23/23 [==============================] - 3s 119ms/step - loss: 0.2543 - acc: 0.9110 - mae: 3.6218 - auc_1: 0.9408\n","Epoch 33/50\n","23/23 [==============================] - 2s 102ms/step - loss: 0.2485 - acc: 0.9138 - mae: 3.5768 - auc_1: 0.9359\n","Epoch 34/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.2478 - acc: 0.9152 - mae: 3.4554 - auc_1: 0.9334\n","Epoch 35/50\n","23/23 [==============================] - 2s 93ms/step - loss: 0.2449 - acc: 0.9138 - mae: 3.4930 - auc_1: 0.9394\n","Epoch 36/50\n","23/23 [==============================] - 2s 90ms/step - loss: 0.2422 - acc: 0.9124 - mae: 3.3756 - auc_1: 0.9377\n","Epoch 37/50\n","23/23 [==============================] - 2s 93ms/step - loss: 0.2433 - acc: 0.9054 - mae: 3.5536 - auc_1: 0.9378\n","Epoch 38/50\n","23/23 [==============================] - 3s 122ms/step - loss: 0.2397 - acc: 0.9068 - mae: 3.2308 - auc_1: 0.9434\n","Epoch 39/50\n","23/23 [==============================] - 2s 104ms/step - loss: 0.2412 - acc: 0.9096 - mae: 3.6263 - auc_1: 0.9329\n","Epoch 40/50\n","23/23 [==============================] - 2s 89ms/step - loss: 0.2420 - acc: 0.9166 - mae: 3.6151 - auc_1: 0.9371\n","Epoch 41/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.2442 - acc: 0.9068 - mae: 3.6359 - auc_1: 0.9356\n","Epoch 42/50\n","23/23 [==============================] - 2s 90ms/step - loss: 0.2395 - acc: 0.9166 - mae: 3.4026 - auc_1: 0.9406\n","Epoch 43/50\n","23/23 [==============================] - 2s 90ms/step - loss: 0.2436 - acc: 0.9026 - mae: 3.6003 - auc_1: 0.9384\n","Epoch 44/50\n","23/23 [==============================] - 3s 116ms/step - loss: 0.2393 - acc: 0.9096 - mae: 3.7167 - auc_1: 0.9314\n","Epoch 45/50\n","23/23 [==============================] - 3s 110ms/step - loss: 0.2506 - acc: 0.9193 - mae: 3.8601 - auc_1: 0.9336\n","Epoch 46/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.2494 - acc: 0.9096 - mae: 3.7671 - auc_1: 0.9278\n","Epoch 47/50\n","23/23 [==============================] - 2s 93ms/step - loss: 0.2393 - acc: 0.9124 - mae: 3.3480 - auc_1: 0.9450\n","Epoch 48/50\n","23/23 [==============================] - 2s 91ms/step - loss: 0.2373 - acc: 0.9082 - mae: 3.5423 - auc_1: 0.9345\n","Epoch 49/50\n","23/23 [==============================] - 2s 89ms/step - loss: 0.2378 - acc: 0.9138 - mae: 3.3335 - auc_1: 0.9409\n","Epoch 50/50\n","23/23 [==============================] - 3s 110ms/step - loss: 0.2397 - acc: 0.9166 - mae: 3.7014 - auc_1: 0.9328\n","Logging Info - Training time: 00:02:25\n","23/23 [==============================] - 0s 3ms/step\n","6/6 [==============================] - 0s 4ms/step\n","\n","Logging Info - Fold 1 Result : {'AUC': 0.9050324675324676, 'ACC': 0.8268156424581006, 'F1 Score': 0.8187134502923977, 'AUPR': 0.9110606298249315}\n","\n","Logging Info - Fold 2 >>>>>>>>>>>>>>\n","\n","test_indices: [50, 135, 527, 618, 861, 488, 806, 97, 656, 809, 443, 644, 230, 221, 42, 643, 892, 603, 684, 359, 813, 111, 18, 154, 701, 320, 284, 179, 293, 145, 536, 489, 871, 173, 183, 85, 296, 693, 36, 823, 732, 573, 291, 558, 785, 889, 480, 309, 203, 312, 531, 474, 34, 369, 275, 416, 240, 826, 78, 357, 336, 860, 171, 437, 204, 541, 815, 616, 873, 588, 339, 382, 540, 137, 397, 867, 575, 595, 289, 15, 473, 354, 733, 884, 454, 106, 829, 331, 610, 308, 304, 352, 9, 658, 324, 457, 802, 524, 585, 782, 687, 39, 286, 79, 407, 519, 64, 217, 673, 717, 55, 810, 234, 770, 164, 439, 384, 706, 799, 313, 459, 869, 735, 563, 513, 220, 842, 377, 492, 707, 208, 266, 33, 321, 493, 11, 560, 771, 198, 117, 584, 872, 580, 231, 746, 666, 364, 214, 705, 875, 630, 479, 131, 366, 360, 170, 754, 635, 126, 58, 188, 721, 504, 142, 199, 825, 719, 796, 471, 608, 348, 762, 832, 242, 195, 664, 546, 521, 699]\n","train_indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 134, 136, 138, 139, 140, 141, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 172, 174, 175, 176, 177, 178, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 196, 197, 200, 201, 202, 205, 206, 207, 209, 210, 211, 212, 213, 215, 216, 218, 219, 222, 223, 224, 225, 226, 227, 228, 229, 232, 233, 235, 236, 237, 238, 239, 241, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 285, 287, 288, 290, 292, 294, 295, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307, 310, 311, 314, 315, 316, 317, 318, 319, 322, 323, 325, 326, 327, 328, 329, 330, 332, 333, 334, 335, 337, 338, 340, 341, 342, 343, 344, 345, 346, 347, 349, 350, 351, 353, 355, 356, 358, 361, 362, 363, 365, 367, 368, 370, 371, 372, 373, 374, 375, 376, 378, 379, 380, 381, 383, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 398, 399, 400, 401, 402, 403, 404, 405, 406, 408, 409, 410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 440, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 455, 456, 458, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 475, 476, 477, 478, 481, 482, 483, 484, 485, 486, 487, 490, 491, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 512, 514, 515, 516, 517, 518, 520, 522, 523, 525, 526, 528, 529, 530, 532, 533, 534, 535, 537, 538, 539, 542, 543, 544, 545, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 559, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572, 574, 576, 577, 578, 579, 581, 582, 583, 586, 587, 589, 590, 591, 592, 593, 594, 596, 597, 598, 599, 600, 601, 602, 604, 605, 606, 607, 609, 611, 612, 613, 614, 615, 617, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 633, 634, 636, 637, 638, 639, 640, 641, 642, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 657, 659, 660, 661, 662, 663, 665, 667, 668, 669, 670, 671, 672, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 685, 686, 688, 689, 690, 691, 692, 694, 695, 696, 697, 698, 700, 702, 703, 704, 708, 709, 710, 711, 712, 713, 714, 715, 716, 718, 720, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 734, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 747, 748, 749, 750, 751, 752, 753, 755, 756, 757, 758, 759, 760, 761, 763, 764, 765, 766, 767, 768, 769, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 783, 784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 797, 798, 800, 801, 803, 804, 805, 807, 808, 811, 812, 814, 816, 817, 818, 819, 820, 821, 822, 824, 827, 828, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 862, 863, 864, 865, 866, 868, 870, 874, 876, 877, 878, 879, 880, 881, 882, 883, 885, 886, 887, 888, 890, 891, 893, 894, 895, 896, 897]\n","\n","first_term2id= {64642: 0, 1667: 1, 50436: 2, 48777: 3, 10506: 4, 33293: 5, 654: 6, 30861: 7, 11153: 8, 64149: 9, 61336: 10, 63129: 11, 13213: 12, 55164: 13, 40873: 14, 34347: 15, 50863: 16, 59444: 17, 22068: 18, 3127: 19, 44991: 20, 66623: 21, 4928: 22, 25026: 23, 7877: 24, 200: 25, 44112: 26, 31069: 27, 54370: 28, 20066: 29, 43621: 30, 66282: 31, 43372: 32, 28016: 33, 12403: 34, 45301: 35, 37496: 36, 9724: 37, 13565: 38} second_term2id= {24065: 0, 19458: 1, 40449: 2, 30212: 3, 12808: 4, 50698: 5, 20492: 6, 46605: 7, 5135: 8, 37392: 9, 42514: 10, 20153: 11, 12824: 12, 37400: 13, 8218: 14, 1049: 15, 30750: 16, 48672: 17, 56353: 18, 52770: 19, 31268: 20, 46117: 21, 10276: 22, 59432: 23, 57903: 24, 2097: 25, 24627: 26, 29241: 27, 50234: 28, 19514: 29, 9788: 30, 14909: 31, 8766: 32, 60987: 33, 64571: 34, 35905: 35, 27202: 36, 26183: 37, 4683: 38, 44108: 39, 33867: 40, 7246: 41, 42577: 42, 61523: 43, 3157: 44, 12374: 45, 3669: 46, 5718: 47, 6745: 48, 64598: 49, 51285: 50, 25176: 51, 35933: 52, 54366: 53, 56416: 54, 35937: 55, 59489: 56, 4707: 57, 4193: 58, 37477: 59, 29281: 60, 35941: 61, 6245: 62, 55403: 63, 18028: 64, 57454: 65, 63599: 66, 54894: 67, 29807: 68, 42610: 69, 62073: 70, 10873: 71, 3195: 72, 46716: 73, 45697: 74, 4739: 75, 47235: 76, 11907: 77, 64132: 78, 41608: 79, 25737: 80, 29322: 81, 65679: 82, 41105: 83, 35986: 84, 38545: 85, 54932: 86, 148: 87, 20627: 88, 45720: 89, 32921: 90, 4251: 91, 53920: 92, 58532: 93, 26788: 94, 15014: 95, 60583: 96, 15528: 97, 46252: 98, 19630: 99, 45746: 100, 179: 101, 47287: 102, 59577: 103, 60601: 104, 43707: 105, 46268: 106, 36028: 107, 15547: 108, 12991: 109, 59584: 110, 52416: 111, 23739: 112, 35015: 113, 13000: 114, 57545: 115, 27335: 116, 25804: 117, 1743: 118, 5846: 119, 45273: 120, 9949: 121, 5344: 122, 63715: 123, 19172: 124, 38632: 125, 1773: 126, 29422: 127, 57582: 128, 48368: 129, 61681: 130, 20724: 131, 35575: 132, 32506: 133, 30970: 134, 16122: 135, 12541: 136, 25341: 137, 56575: 138, 34048: 139, 11010: 140, 7427: 141, 15620: 142, 45317: 143, 35590: 144, 28933: 145, 47880: 146, 34574: 147, 61711: 148, 23823: 149, 57617: 150, 20754: 151, 23314: 152, 5396: 153, 58642: 154, 65813: 155, 28944: 156, 23832: 157, 65819: 158, 44316: 159, 27935: 160, 8480: 161, 25376: 162, 19744: 163, 6432: 164, 55588: 165, 51493: 166, 1823: 167, 40740: 168, 14120: 169, 8488: 170, 56106: 171, 12583: 172, 32044: 173, 53038: 174, 64304: 175, 62257: 176, 34610: 177, 5427: 178, 51508: 179, 6454: 180, 15670: 181, 39226: 182, 63804: 183, 10559: 184, 60226: 185, 22850: 186, 16707: 187, 10565: 188, 35142: 189, 49992: 190, 13641: 191, 18765: 192, 6993: 193, 54098: 194, 7506: 195, 59219: 196, 7507: 197, 11601: 198, 32087: 199, 25943: 200, 7516: 201, 65885: 202, 32606: 203, 40800: 204, 31584: 205, 57696: 206, 60261: 207, 30566: 208, 39272: 209, 50024: 210, 63336: 211, 52077: 212, 878: 213, 13682: 214, 26995: 215, 25460: 216, 27509: 217, 19319: 218, 32631: 219, 4986: 220, 32635: 221, 3965: 222, 40832: 223, 59776: 224, 32642: 225, 5508: 226, 57221: 227, 20358: 228, 7051: 229, 48011: 230, 56210: 231, 19860: 232, 56727: 233, 53656: 234, 926: 235, 49054: 236, 29598: 237, 48031: 238, 53155: 239, 55203: 240, 33701: 241, 18341: 242, 39335: 243, 6056: 244, 15268: 245, 32170: 246, 61356: 247, 431: 248, 8113: 249, 33201: 250, 34740: 251, 7093: 252, 54199: 253, 28601: 254, 25018: 255, 33211: 256, 25020: 257, 41916: 258, 30654: 259, 11709: 260, 57280: 261, 12223: 262, 53186: 263, 10691: 264, 26565: 265, 34758: 266, 9670: 267, 7114: 268, 34763: 269, 3530: 270, 14286: 271, 51153: 272, 22484: 273, 16341: 274, 54235: 275, 41953: 276, 32254: 277, 56808: 278, 29163: 279, 4589: 280, 46062: 281, 63471: 282, 53233: 283, 21490: 284, 18423: 285, 23544: 286, 65017: 287, 6651: 288, 33790: 289, 23039: 290}\n","KerasTensor(type_spec=TensorSpec(shape=(None, 71), dtype=tf.float32, name=None), name='lambda_3/concat:0', description=\"created by layer 'lambda_3'\")\n","Epoch 1/50\n","23/23 [==============================] - 6s 93ms/step - loss: 3.1701 - acc: 0.7121 - mae: 2.1655 - auc: 0.8186\n","Epoch 2/50\n","23/23 [==============================] - 2s 95ms/step - loss: 2.2947 - acc: 0.8512 - mae: 2.7403 - auc: 0.9022\n","Epoch 3/50\n","23/23 [==============================] - 3s 117ms/step - loss: 1.8773 - acc: 0.8804 - mae: 2.7275 - auc: 0.9205\n","Epoch 4/50\n","23/23 [==============================] - 2s 99ms/step - loss: 1.5571 - acc: 0.8915 - mae: 3.0013 - auc: 0.9194\n","Epoch 5/50\n","23/23 [==============================] - 2s 91ms/step - loss: 1.3037 - acc: 0.8929 - mae: 2.9259 - auc: 0.9300\n","Epoch 6/50\n","23/23 [==============================] - 2s 92ms/step - loss: 1.0993 - acc: 0.8985 - mae: 3.3414 - auc: 0.9347\n","Epoch 7/50\n","23/23 [==============================] - 2s 89ms/step - loss: 0.9373 - acc: 0.8999 - mae: 3.4553 - auc: 0.9304\n","Epoch 8/50\n","23/23 [==============================] - 2s 90ms/step - loss: 0.8182 - acc: 0.8971 - mae: 3.1725 - auc: 0.9378\n","Epoch 9/50\n","23/23 [==============================] - 2s 109ms/step - loss: 0.6997 - acc: 0.9082 - mae: 3.6107 - auc: 0.9372\n","Epoch 10/50\n","23/23 [==============================] - 3s 113ms/step - loss: 0.6159 - acc: 0.9096 - mae: 3.4572 - auc: 0.9381\n","Epoch 11/50\n","23/23 [==============================] - 2s 89ms/step - loss: 0.5420 - acc: 0.9124 - mae: 3.6080 - auc: 0.9350\n","Epoch 12/50\n","23/23 [==============================] - 2s 87ms/step - loss: 0.4865 - acc: 0.9054 - mae: 3.7532 - auc: 0.9366\n","Epoch 13/50\n","23/23 [==============================] - 2s 93ms/step - loss: 0.4446 - acc: 0.9152 - mae: 3.5548 - auc: 0.9424\n","Epoch 14/50\n","23/23 [==============================] - 2s 90ms/step - loss: 0.4021 - acc: 0.9054 - mae: 3.5824 - auc: 0.9403\n","Epoch 15/50\n","23/23 [==============================] - 2s 93ms/step - loss: 0.3732 - acc: 0.9166 - mae: 3.6355 - auc: 0.9443\n","Epoch 16/50\n","23/23 [==============================] - 3s 111ms/step - loss: 0.3538 - acc: 0.9124 - mae: 3.8957 - auc: 0.9399\n","Epoch 17/50\n","23/23 [==============================] - 2s 100ms/step - loss: 0.3328 - acc: 0.9096 - mae: 3.8805 - auc: 0.9359\n","Epoch 18/50\n","23/23 [==============================] - 2s 89ms/step - loss: 0.3174 - acc: 0.9054 - mae: 3.8710 - auc: 0.9401\n","Epoch 19/50\n","23/23 [==============================] - 2s 89ms/step - loss: 0.3013 - acc: 0.9152 - mae: 3.7964 - auc: 0.9418\n","Epoch 20/50\n","23/23 [==============================] - 2s 91ms/step - loss: 0.2901 - acc: 0.9082 - mae: 3.8894 - auc: 0.9369\n","Epoch 21/50\n","23/23 [==============================] - 2s 89ms/step - loss: 0.2851 - acc: 0.9110 - mae: 4.1209 - auc: 0.9452\n","Epoch 22/50\n","23/23 [==============================] - 2s 107ms/step - loss: 0.2844 - acc: 0.9124 - mae: 4.0660 - auc: 0.9383\n","Epoch 23/50\n","23/23 [==============================] - 3s 113ms/step - loss: 0.2691 - acc: 0.9152 - mae: 3.6728 - auc: 0.9446\n","Epoch 24/50\n","23/23 [==============================] - 2s 89ms/step - loss: 0.2673 - acc: 0.9013 - mae: 3.8656 - auc: 0.9364\n","Epoch 25/50\n","23/23 [==============================] - 2s 89ms/step - loss: 0.2583 - acc: 0.9138 - mae: 3.7977 - auc: 0.9486\n","Epoch 26/50\n","23/23 [==============================] - 2s 90ms/step - loss: 0.2521 - acc: 0.9152 - mae: 3.9026 - auc: 0.9423\n","Epoch 27/50\n","23/23 [==============================] - 2s 91ms/step - loss: 0.2487 - acc: 0.9193 - mae: 3.8603 - auc: 0.9410\n","Epoch 28/50\n","23/23 [==============================] - 2s 96ms/step - loss: 0.2498 - acc: 0.9166 - mae: 3.6316 - auc: 0.9407\n","Epoch 29/50\n","23/23 [==============================] - 3s 113ms/step - loss: 0.2502 - acc: 0.9110 - mae: 3.8743 - auc: 0.9354\n","Epoch 30/50\n","23/23 [==============================] - 2s 100ms/step - loss: 0.2432 - acc: 0.9166 - mae: 3.8330 - auc: 0.9388\n","Epoch 31/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.2432 - acc: 0.9207 - mae: 3.8011 - auc: 0.9457\n","Epoch 32/50\n","23/23 [==============================] - 2s 90ms/step - loss: 0.2453 - acc: 0.9110 - mae: 4.0066 - auc: 0.9399\n","Epoch 33/50\n","23/23 [==============================] - 2s 88ms/step - loss: 0.2526 - acc: 0.9054 - mae: 4.7618 - auc: 0.9291\n","Epoch 34/50\n","23/23 [==============================] - 2s 90ms/step - loss: 0.2491 - acc: 0.9110 - mae: 3.8613 - auc: 0.9370\n","Epoch 35/50\n","23/23 [==============================] - 3s 111ms/step - loss: 0.2358 - acc: 0.9193 - mae: 3.6864 - auc: 0.9452\n","Epoch 36/50\n","23/23 [==============================] - 3s 113ms/step - loss: 0.2416 - acc: 0.9138 - mae: 4.0082 - auc: 0.9415\n","Epoch 37/50\n","23/23 [==============================] - 2s 91ms/step - loss: 0.2347 - acc: 0.9152 - mae: 3.6864 - auc: 0.9485\n","Epoch 38/50\n","23/23 [==============================] - 2s 102ms/step - loss: 0.2374 - acc: 0.9026 - mae: 4.0081 - auc: 0.9448\n","Epoch 39/50\n","23/23 [==============================] - 3s 117ms/step - loss: 0.2332 - acc: 0.9096 - mae: 4.1728 - auc: 0.9365\n","Epoch 40/50\n","23/23 [==============================] - 2s 97ms/step - loss: 0.2396 - acc: 0.9110 - mae: 3.5285 - auc: 0.9434\n","Epoch 41/50\n","23/23 [==============================] - 3s 114ms/step - loss: 0.2368 - acc: 0.9040 - mae: 4.2235 - auc: 0.9399\n","Epoch 42/50\n","23/23 [==============================] - 3s 110ms/step - loss: 0.2398 - acc: 0.9082 - mae: 4.1459 - auc: 0.9391\n","Epoch 43/50\n","23/23 [==============================] - 2s 90ms/step - loss: 0.2356 - acc: 0.9179 - mae: 3.7817 - auc: 0.9419\n","Epoch 44/50\n","23/23 [==============================] - 2s 93ms/step - loss: 0.2330 - acc: 0.9068 - mae: 4.0468 - auc: 0.9386\n","Epoch 45/50\n","23/23 [==============================] - 2s 90ms/step - loss: 0.2308 - acc: 0.9193 - mae: 3.8266 - auc: 0.9392\n","Epoch 46/50\n","23/23 [==============================] - 2s 88ms/step - loss: 0.2293 - acc: 0.9124 - mae: 3.7673 - auc: 0.9444\n","Epoch 47/50\n","23/23 [==============================] - 2s 106ms/step - loss: 0.2307 - acc: 0.9166 - mae: 3.9555 - auc: 0.9388\n","Epoch 48/50\n","23/23 [==============================] - 3s 118ms/step - loss: 0.2351 - acc: 0.9152 - mae: 3.8506 - auc: 0.9427\n","Epoch 49/50\n","23/23 [==============================] - 2s 91ms/step - loss: 0.2398 - acc: 0.9082 - mae: 4.0465 - auc: 0.9300\n","Epoch 50/50\n","23/23 [==============================] - 2s 89ms/step - loss: 0.2312 - acc: 0.9082 - mae: 3.9323 - auc: 0.9371\n","Logging Info - Training time: 00:02:25\n","23/23 [==============================] - 1s 6ms/step\n","6/6 [==============================] - 0s 6ms/step\n","\n","Logging Info - Fold 2 Result : {'AUC': 0.9034133533383346, 'ACC': 0.7988826815642458, 'F1 Score': 0.783132530120482, 'AUPR': 0.8976527915072785}\n","\n","Logging Info - Fold 3 >>>>>>>>>>>>>>\n","\n","test_indices: [66, 158, 452, 65, 119, 253, 743, 486, 302, 888, 41, 212, 533, 772, 891, 181, 393, 103, 92, 744, 209, 238, 435, 783, 672, 353, 62, 836, 191, 786, 482, 417, 89, 310, 426, 95, 828, 606, 864, 375, 40, 716, 422, 611, 696, 574, 725, 740, 29, 73, 516, 526, 592, 581, 362, 491, 622, 249, 625, 591, 227, 338, 264, 410, 404, 197, 674, 844, 688, 423, 14, 428, 112, 67, 149, 792, 509, 627, 277, 465, 794, 116, 549, 887, 628, 421, 503, 857, 373, 812, 525, 265, 749, 202, 45, 178, 614, 150, 577, 391, 125, 847, 381, 645, 438, 152, 235, 596, 833, 436, 368, 824, 200, 3, 246, 613, 394, 261, 753, 165, 68, 808, 101, 547, 17, 624, 444, 30, 476, 501, 133, 326, 512, 468, 768, 726, 47, 804, 383, 22, 307, 267, 817, 401, 411, 361, 441, 207, 358, 659, 272, 148, 276, 157, 773, 838, 88, 466, 96, 831, 561, 897, 274, 333, 548, 853, 429, 104, 751, 578, 537, 315, 572, 538, 787, 281, 298, 153, 850]\n","train_indices: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 93, 94, 97, 98, 99, 100, 102, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 151, 154, 155, 156, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 198, 199, 201, 203, 204, 205, 206, 208, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 239, 240, 241, 242, 243, 244, 245, 247, 248, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 262, 263, 266, 268, 269, 270, 271, 273, 275, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 300, 301, 303, 304, 305, 306, 308, 309, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 359, 360, 363, 364, 365, 366, 367, 369, 370, 371, 372, 374, 376, 377, 378, 379, 380, 382, 384, 385, 386, 387, 388, 389, 390, 392, 395, 396, 397, 398, 399, 400, 402, 403, 405, 406, 407, 408, 409, 412, 413, 414, 415, 416, 418, 419, 420, 424, 425, 427, 430, 431, 432, 433, 434, 437, 439, 440, 442, 443, 445, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 467, 469, 470, 471, 472, 473, 474, 475, 477, 478, 479, 480, 481, 483, 484, 485, 487, 488, 489, 490, 492, 493, 494, 495, 496, 497, 498, 499, 500, 502, 504, 505, 506, 507, 508, 510, 511, 513, 514, 515, 517, 518, 519, 520, 521, 522, 523, 524, 527, 528, 529, 530, 531, 532, 534, 535, 536, 539, 540, 541, 542, 543, 544, 545, 546, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 573, 575, 576, 579, 580, 582, 583, 584, 585, 586, 587, 588, 589, 590, 593, 594, 595, 597, 598, 599, 600, 601, 602, 603, 604, 605, 607, 608, 609, 610, 612, 615, 616, 617, 618, 619, 620, 621, 623, 626, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 689, 690, 691, 692, 693, 694, 695, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 717, 718, 719, 720, 721, 722, 723, 724, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 741, 742, 745, 746, 747, 748, 750, 752, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 769, 770, 771, 774, 775, 776, 777, 778, 779, 780, 781, 782, 784, 785, 788, 789, 790, 791, 793, 795, 796, 797, 798, 799, 800, 801, 802, 803, 805, 806, 807, 809, 810, 811, 813, 814, 815, 816, 818, 819, 820, 821, 822, 823, 825, 826, 827, 829, 830, 832, 834, 835, 837, 839, 840, 841, 842, 843, 845, 846, 848, 849, 851, 852, 854, 855, 856, 858, 859, 860, 861, 862, 863, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 889, 890, 892, 893, 894, 895, 896]\n","\n","first_term2id= {64642: 0, 1667: 1, 50436: 2, 48777: 3, 10506: 4, 33293: 5, 654: 6, 30861: 7, 11153: 8, 64149: 9, 61336: 10, 63129: 11, 13213: 12, 55164: 13, 40873: 14, 34347: 15, 50863: 16, 59444: 17, 22068: 18, 3127: 19, 44991: 20, 66623: 21, 4928: 22, 25026: 23, 7877: 24, 200: 25, 44112: 26, 31069: 27, 54370: 28, 20066: 29, 43621: 30, 66282: 31, 43372: 32, 28016: 33, 12403: 34, 45301: 35, 37496: 36, 9724: 37, 13565: 38} second_term2id= {24065: 0, 19458: 1, 40449: 2, 30212: 3, 12808: 4, 50698: 5, 20492: 6, 46605: 7, 5135: 8, 37392: 9, 42514: 10, 20153: 11, 12824: 12, 37400: 13, 8218: 14, 1049: 15, 30750: 16, 48672: 17, 56353: 18, 52770: 19, 31268: 20, 46117: 21, 10276: 22, 59432: 23, 57903: 24, 2097: 25, 24627: 26, 29241: 27, 50234: 28, 19514: 29, 9788: 30, 14909: 31, 8766: 32, 60987: 33, 64571: 34, 35905: 35, 27202: 36, 26183: 37, 4683: 38, 44108: 39, 33867: 40, 7246: 41, 42577: 42, 61523: 43, 3157: 44, 12374: 45, 3669: 46, 5718: 47, 6745: 48, 64598: 49, 51285: 50, 25176: 51, 35933: 52, 54366: 53, 56416: 54, 35937: 55, 59489: 56, 4707: 57, 4193: 58, 37477: 59, 29281: 60, 35941: 61, 6245: 62, 55403: 63, 18028: 64, 57454: 65, 63599: 66, 54894: 67, 29807: 68, 42610: 69, 62073: 70, 10873: 71, 3195: 72, 46716: 73, 45697: 74, 4739: 75, 47235: 76, 11907: 77, 64132: 78, 41608: 79, 25737: 80, 29322: 81, 65679: 82, 41105: 83, 35986: 84, 38545: 85, 54932: 86, 148: 87, 20627: 88, 45720: 89, 32921: 90, 4251: 91, 53920: 92, 58532: 93, 26788: 94, 15014: 95, 60583: 96, 15528: 97, 46252: 98, 19630: 99, 45746: 100, 179: 101, 47287: 102, 59577: 103, 60601: 104, 43707: 105, 46268: 106, 36028: 107, 15547: 108, 12991: 109, 59584: 110, 52416: 111, 23739: 112, 35015: 113, 13000: 114, 57545: 115, 27335: 116, 25804: 117, 1743: 118, 5846: 119, 45273: 120, 9949: 121, 5344: 122, 63715: 123, 19172: 124, 38632: 125, 1773: 126, 29422: 127, 57582: 128, 48368: 129, 61681: 130, 20724: 131, 35575: 132, 32506: 133, 30970: 134, 16122: 135, 12541: 136, 25341: 137, 56575: 138, 34048: 139, 11010: 140, 7427: 141, 15620: 142, 45317: 143, 35590: 144, 28933: 145, 47880: 146, 34574: 147, 61711: 148, 23823: 149, 57617: 150, 20754: 151, 23314: 152, 5396: 153, 58642: 154, 65813: 155, 28944: 156, 23832: 157, 65819: 158, 44316: 159, 27935: 160, 8480: 161, 25376: 162, 19744: 163, 6432: 164, 55588: 165, 51493: 166, 1823: 167, 40740: 168, 14120: 169, 8488: 170, 56106: 171, 12583: 172, 32044: 173, 53038: 174, 64304: 175, 62257: 176, 34610: 177, 5427: 178, 51508: 179, 6454: 180, 15670: 181, 39226: 182, 63804: 183, 10559: 184, 60226: 185, 22850: 186, 16707: 187, 10565: 188, 35142: 189, 49992: 190, 13641: 191, 18765: 192, 6993: 193, 54098: 194, 7506: 195, 59219: 196, 7507: 197, 11601: 198, 32087: 199, 25943: 200, 7516: 201, 65885: 202, 32606: 203, 40800: 204, 31584: 205, 57696: 206, 60261: 207, 30566: 208, 39272: 209, 50024: 210, 63336: 211, 52077: 212, 878: 213, 13682: 214, 26995: 215, 25460: 216, 27509: 217, 19319: 218, 32631: 219, 4986: 220, 32635: 221, 3965: 222, 40832: 223, 59776: 224, 32642: 225, 5508: 226, 57221: 227, 20358: 228, 7051: 229, 48011: 230, 56210: 231, 19860: 232, 56727: 233, 53656: 234, 926: 235, 49054: 236, 29598: 237, 48031: 238, 53155: 239, 55203: 240, 33701: 241, 18341: 242, 39335: 243, 6056: 244, 15268: 245, 32170: 246, 61356: 247, 431: 248, 8113: 249, 33201: 250, 34740: 251, 7093: 252, 54199: 253, 28601: 254, 25018: 255, 33211: 256, 25020: 257, 41916: 258, 30654: 259, 11709: 260, 57280: 261, 12223: 262, 53186: 263, 10691: 264, 26565: 265, 34758: 266, 9670: 267, 7114: 268, 34763: 269, 3530: 270, 14286: 271, 51153: 272, 22484: 273, 16341: 274, 54235: 275, 41953: 276, 32254: 277, 56808: 278, 29163: 279, 4589: 280, 46062: 281, 63471: 282, 53233: 283, 21490: 284, 18423: 285, 23544: 286, 65017: 287, 6651: 288, 33790: 289, 23039: 290}\n","KerasTensor(type_spec=TensorSpec(shape=(None, 71), dtype=tf.float32, name=None), name='lambda_3/concat:0', description=\"created by layer 'lambda_3'\")\n","Epoch 1/50\n","23/23 [==============================] - 6s 95ms/step - loss: 3.2183 - acc: 0.6509 - mae: 2.8505 - auc: 0.7344\n","Epoch 2/50\n","23/23 [==============================] - 2s 93ms/step - loss: 2.3163 - acc: 0.8289 - mae: 2.7173 - auc: 0.8753\n","Epoch 3/50\n","23/23 [==============================] - 2s 93ms/step - loss: 1.9120 - acc: 0.8637 - mae: 2.5668 - auc: 0.9138\n","Epoch 4/50\n","23/23 [==============================] - 2s 108ms/step - loss: 1.6045 - acc: 0.8832 - mae: 2.7985 - auc: 0.9216\n","Epoch 5/50\n","23/23 [==============================] - 3s 115ms/step - loss: 1.3550 - acc: 0.8901 - mae: 2.8683 - auc: 0.9242\n","Epoch 6/50\n","23/23 [==============================] - 2s 88ms/step - loss: 1.1531 - acc: 0.8929 - mae: 3.0844 - auc: 0.9279\n","Epoch 7/50\n","23/23 [==============================] - 2s 91ms/step - loss: 0.9869 - acc: 0.9026 - mae: 3.0230 - auc: 0.9325\n","Epoch 8/50\n","23/23 [==============================] - 2s 96ms/step - loss: 0.8528 - acc: 0.9013 - mae: 3.3512 - auc: 0.9318\n","Epoch 9/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.7499 - acc: 0.9068 - mae: 3.2527 - auc: 0.9329\n","Epoch 10/50\n","23/23 [==============================] - 2s 103ms/step - loss: 0.6534 - acc: 0.9166 - mae: 3.1998 - auc: 0.9395\n","Epoch 11/50\n","23/23 [==============================] - 3s 120ms/step - loss: 0.5846 - acc: 0.9110 - mae: 3.3593 - auc: 0.9405\n","Epoch 12/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.5318 - acc: 0.9110 - mae: 3.6317 - auc: 0.9269\n","Epoch 13/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.4749 - acc: 0.9096 - mae: 3.5866 - auc: 0.9366\n","Epoch 14/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.4325 - acc: 0.9082 - mae: 3.4353 - auc: 0.9399\n","Epoch 15/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.4014 - acc: 0.9096 - mae: 3.5801 - auc: 0.9383\n","Epoch 16/50\n","23/23 [==============================] - 2s 95ms/step - loss: 0.3735 - acc: 0.9096 - mae: 3.3224 - auc: 0.9450\n","Epoch 17/50\n","23/23 [==============================] - 3s 120ms/step - loss: 0.3512 - acc: 0.9040 - mae: 3.6623 - auc: 0.9356\n","Epoch 18/50\n","23/23 [==============================] - 2s 104ms/step - loss: 0.3372 - acc: 0.9124 - mae: 3.7071 - auc: 0.9374\n","Epoch 19/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.3217 - acc: 0.9138 - mae: 3.6223 - auc: 0.9391\n","Epoch 20/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.3064 - acc: 0.9110 - mae: 3.5345 - auc: 0.9425\n","Epoch 21/50\n","23/23 [==============================] - 2s 93ms/step - loss: 0.2947 - acc: 0.9138 - mae: 3.5221 - auc: 0.9449\n","Epoch 22/50\n","23/23 [==============================] - 2s 95ms/step - loss: 0.2927 - acc: 0.9096 - mae: 3.7259 - auc: 0.9318\n","Epoch 23/50\n","23/23 [==============================] - 3s 119ms/step - loss: 0.2787 - acc: 0.9082 - mae: 3.5414 - auc: 0.9390\n","Epoch 24/50\n","23/23 [==============================] - 3s 111ms/step - loss: 0.2727 - acc: 0.9054 - mae: 3.6673 - auc: 0.9387\n","Epoch 25/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.2672 - acc: 0.9110 - mae: 3.6253 - auc: 0.9427\n","Epoch 26/50\n","23/23 [==============================] - 2s 93ms/step - loss: 0.2602 - acc: 0.9110 - mae: 3.6059 - auc: 0.9458\n","Epoch 27/50\n","23/23 [==============================] - 2s 95ms/step - loss: 0.2661 - acc: 0.9152 - mae: 3.7822 - auc: 0.9440\n","Epoch 28/50\n","23/23 [==============================] - 2s 95ms/step - loss: 0.2561 - acc: 0.9068 - mae: 3.9696 - auc: 0.9321\n","Epoch 29/50\n","23/23 [==============================] - 3s 114ms/step - loss: 0.2533 - acc: 0.9068 - mae: 3.7662 - auc: 0.9324\n","Epoch 30/50\n","23/23 [==============================] - 3s 111ms/step - loss: 0.2590 - acc: 0.9166 - mae: 3.5953 - auc: 0.9336\n","Epoch 31/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.2486 - acc: 0.9152 - mae: 3.7636 - auc: 0.9350\n","Epoch 32/50\n","23/23 [==============================] - 2s 89ms/step - loss: 0.2461 - acc: 0.9152 - mae: 3.5311 - auc: 0.9402\n","Epoch 33/50\n","23/23 [==============================] - 2s 95ms/step - loss: 0.2432 - acc: 0.9096 - mae: 3.6569 - auc: 0.9400\n","Epoch 34/50\n","23/23 [==============================] - 2s 95ms/step - loss: 0.2404 - acc: 0.9138 - mae: 3.5004 - auc: 0.9457\n","Epoch 35/50\n","23/23 [==============================] - 2s 103ms/step - loss: 0.2393 - acc: 0.9096 - mae: 3.7987 - auc: 0.9416\n","Epoch 36/50\n","23/23 [==============================] - 3s 124ms/step - loss: 0.2401 - acc: 0.9138 - mae: 3.5809 - auc: 0.9464\n","Epoch 37/50\n","23/23 [==============================] - 2s 93ms/step - loss: 0.2405 - acc: 0.9068 - mae: 3.7675 - auc: 0.9377\n","Epoch 38/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.2371 - acc: 0.9193 - mae: 3.5446 - auc: 0.9414\n","Epoch 39/50\n","23/23 [==============================] - 2s 91ms/step - loss: 0.2383 - acc: 0.9068 - mae: 3.7794 - auc: 0.9430\n","Epoch 40/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.2366 - acc: 0.9124 - mae: 3.6257 - auc: 0.9454\n","Epoch 41/50\n","23/23 [==============================] - 2s 98ms/step - loss: 0.2394 - acc: 0.9082 - mae: 3.6982 - auc: 0.9437\n","Epoch 42/50\n","23/23 [==============================] - 3s 111ms/step - loss: 0.2328 - acc: 0.9068 - mae: 3.8069 - auc: 0.9416\n","Epoch 43/50\n","23/23 [==============================] - 2s 103ms/step - loss: 0.2376 - acc: 0.9152 - mae: 3.6187 - auc: 0.9425\n","Epoch 44/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.2451 - acc: 0.9138 - mae: 4.1246 - auc: 0.9328\n","Epoch 45/50\n","23/23 [==============================] - 2s 91ms/step - loss: 0.2466 - acc: 0.9096 - mae: 4.0482 - auc: 0.9341\n","Epoch 46/50\n","23/23 [==============================] - 2s 91ms/step - loss: 0.2374 - acc: 0.9152 - mae: 3.6403 - auc: 0.9401\n","Epoch 47/50\n","23/23 [==============================] - 2s 94ms/step - loss: 0.2336 - acc: 0.9138 - mae: 3.7754 - auc: 0.9392\n","Epoch 48/50\n","23/23 [==============================] - 3s 118ms/step - loss: 0.2301 - acc: 0.9040 - mae: 3.6746 - auc: 0.9429\n","Epoch 49/50\n","23/23 [==============================] - 3s 112ms/step - loss: 0.2330 - acc: 0.9082 - mae: 3.6165 - auc: 0.9442\n","Epoch 50/50\n","23/23 [==============================] - 2s 92ms/step - loss: 0.2302 - acc: 0.9096 - mae: 3.4754 - auc: 0.9506\n","Logging Info - Training time: 00:02:26\n","23/23 [==============================] - 1s 3ms/step\n","6/6 [==============================] - 0s 4ms/step\n","\n","Logging Info - Fold 3 Result : {'AUC': 0.8972215237616293, 'ACC': 0.8212290502793296, 'F1 Score': 0.8160919540229885, 'AUPR': 0.9272575921258005}\n","\n","Logging Info - Fold 4 >>>>>>>>>>>>>>\n","\n","test_indices: [567, 442, 303, 679, 367, 19, 849, 160, 711, 494, 0, 858, 662, 896, 295, 52, 129, 709, 6, 279, 510, 805, 583, 155, 617, 514, 16, 880, 621, 814, 756, 257, 634, 61, 270, 819, 811, 798, 865, 334, 472, 551, 59, 692, 490, 162, 258, 328, 686, 820, 297, 839, 144, 498, 691, 194, 661, 741, 49, 285, 769, 502, 760, 115, 587, 821, 250, 729, 882, 544, 8, 205, 12, 736, 801, 134, 420, 176, 233, 765, 455, 177, 187, 43, 568, 108, 386, 795, 418, 254, 146, 82, 840, 219, 251, 355, 408, 467, 26, 403, 76, 329, 239, 463, 216, 694, 780, 668, 739, 475, 859, 647, 232, 885, 311, 543, 458, 648, 211, 781, 271, 708, 23, 677, 685, 399, 141, 218, 863, 243, 175, 406, 398, 424, 74, 269, 156, 803, 738, 387, 166, 690, 816, 545, 94, 371, 206, 192, 807, 784, 347, 226, 151, 678, 827, 619, 323, 186, 273, 385, 24, 846, 343, 856, 446, 556, 697, 854, 788, 890, 565, 722, 300, 93, 702, 777, 508, 615, 229]\n","train_indices: [1, 2, 3, 4, 5, 7, 9, 10, 11, 13, 14, 15, 17, 18, 20, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 145, 147, 148, 149, 150, 152, 153, 154, 157, 158, 159, 161, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 178, 179, 180, 181, 182, 183, 184, 185, 188, 189, 190, 191, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 207, 208, 209, 210, 212, 213, 214, 215, 217, 220, 221, 222, 223, 224, 225, 227, 228, 230, 231, 234, 235, 236, 237, 238, 240, 241, 242, 244, 245, 246, 247, 248, 249, 252, 253, 255, 256, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 272, 274, 275, 276, 277, 278, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 304, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342, 344, 345, 346, 348, 349, 350, 351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 400, 401, 402, 404, 405, 407, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 421, 422, 423, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 443, 444, 445, 447, 448, 449, 450, 451, 452, 453, 454, 456, 457, 459, 460, 461, 462, 464, 465, 466, 468, 469, 470, 471, 473, 474, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 491, 492, 493, 495, 496, 497, 499, 500, 501, 503, 504, 505, 506, 507, 509, 511, 512, 513, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 546, 547, 548, 549, 550, 552, 553, 554, 555, 557, 558, 559, 560, 561, 562, 563, 564, 566, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 584, 585, 586, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 616, 618, 620, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 663, 664, 665, 666, 667, 669, 670, 671, 672, 673, 674, 675, 676, 680, 681, 682, 683, 684, 687, 688, 689, 693, 695, 696, 698, 699, 700, 701, 703, 704, 705, 706, 707, 710, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 723, 724, 725, 726, 727, 728, 730, 731, 732, 733, 734, 735, 737, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 757, 758, 759, 761, 762, 763, 764, 766, 767, 768, 770, 771, 772, 773, 774, 775, 776, 778, 779, 782, 783, 785, 786, 787, 789, 790, 791, 792, 793, 794, 796, 797, 799, 800, 802, 804, 806, 808, 809, 810, 812, 813, 815, 817, 818, 822, 823, 824, 825, 826, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 841, 842, 843, 844, 845, 847, 848, 850, 851, 852, 853, 855, 857, 860, 861, 862, 864, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 881, 883, 884, 886, 887, 888, 889, 891, 892, 893, 894, 895, 897]\n","\n","first_term2id= {64642: 0, 1667: 1, 50436: 2, 48777: 3, 10506: 4, 33293: 5, 654: 6, 30861: 7, 11153: 8, 64149: 9, 61336: 10, 63129: 11, 13213: 12, 55164: 13, 40873: 14, 34347: 15, 50863: 16, 59444: 17, 22068: 18, 3127: 19, 44991: 20, 66623: 21, 4928: 22, 25026: 23, 7877: 24, 200: 25, 44112: 26, 31069: 27, 54370: 28, 20066: 29, 43621: 30, 66282: 31, 43372: 32, 28016: 33, 12403: 34, 45301: 35, 37496: 36, 9724: 37, 13565: 38} second_term2id= {24065: 0, 19458: 1, 40449: 2, 30212: 3, 12808: 4, 50698: 5, 20492: 6, 46605: 7, 5135: 8, 37392: 9, 42514: 10, 20153: 11, 12824: 12, 37400: 13, 8218: 14, 1049: 15, 30750: 16, 48672: 17, 56353: 18, 52770: 19, 31268: 20, 46117: 21, 10276: 22, 59432: 23, 57903: 24, 2097: 25, 24627: 26, 29241: 27, 50234: 28, 19514: 29, 9788: 30, 14909: 31, 8766: 32, 60987: 33, 64571: 34, 35905: 35, 27202: 36, 26183: 37, 4683: 38, 44108: 39, 33867: 40, 7246: 41, 42577: 42, 61523: 43, 3157: 44, 12374: 45, 3669: 46, 5718: 47, 6745: 48, 64598: 49, 51285: 50, 25176: 51, 35933: 52, 54366: 53, 56416: 54, 35937: 55, 59489: 56, 4707: 57, 4193: 58, 37477: 59, 29281: 60, 35941: 61, 6245: 62, 55403: 63, 18028: 64, 57454: 65, 63599: 66, 54894: 67, 29807: 68, 42610: 69, 62073: 70, 10873: 71, 3195: 72, 46716: 73, 45697: 74, 4739: 75, 47235: 76, 11907: 77, 64132: 78, 41608: 79, 25737: 80, 29322: 81, 65679: 82, 41105: 83, 35986: 84, 38545: 85, 54932: 86, 148: 87, 20627: 88, 45720: 89, 32921: 90, 4251: 91, 53920: 92, 58532: 93, 26788: 94, 15014: 95, 60583: 96, 15528: 97, 46252: 98, 19630: 99, 45746: 100, 179: 101, 47287: 102, 59577: 103, 60601: 104, 43707: 105, 46268: 106, 36028: 107, 15547: 108, 12991: 109, 59584: 110, 52416: 111, 23739: 112, 35015: 113, 13000: 114, 57545: 115, 27335: 116, 25804: 117, 1743: 118, 5846: 119, 45273: 120, 9949: 121, 5344: 122, 63715: 123, 19172: 124, 38632: 125, 1773: 126, 29422: 127, 57582: 128, 48368: 129, 61681: 130, 20724: 131, 35575: 132, 32506: 133, 30970: 134, 16122: 135, 12541: 136, 25341: 137, 56575: 138, 34048: 139, 11010: 140, 7427: 141, 15620: 142, 45317: 143, 35590: 144, 28933: 145, 47880: 146, 34574: 147, 61711: 148, 23823: 149, 57617: 150, 20754: 151, 23314: 152, 5396: 153, 58642: 154, 65813: 155, 28944: 156, 23832: 157, 65819: 158, 44316: 159, 27935: 160, 8480: 161, 25376: 162, 19744: 163, 6432: 164, 55588: 165, 51493: 166, 1823: 167, 40740: 168, 14120: 169, 8488: 170, 56106: 171, 12583: 172, 32044: 173, 53038: 174, 64304: 175, 62257: 176, 34610: 177, 5427: 178, 51508: 179, 6454: 180, 15670: 181, 39226: 182, 63804: 183, 10559: 184, 60226: 185, 22850: 186, 16707: 187, 10565: 188, 35142: 189, 49992: 190, 13641: 191, 18765: 192, 6993: 193, 54098: 194, 7506: 195, 59219: 196, 7507: 197, 11601: 198, 32087: 199, 25943: 200, 7516: 201, 65885: 202, 32606: 203, 40800: 204, 31584: 205, 57696: 206, 60261: 207, 30566: 208, 39272: 209, 50024: 210, 63336: 211, 52077: 212, 878: 213, 13682: 214, 26995: 215, 25460: 216, 27509: 217, 19319: 218, 32631: 219, 4986: 220, 32635: 221, 3965: 222, 40832: 223, 59776: 224, 32642: 225, 5508: 226, 57221: 227, 20358: 228, 7051: 229, 48011: 230, 56210: 231, 19860: 232, 56727: 233, 53656: 234, 926: 235, 49054: 236, 29598: 237, 48031: 238, 53155: 239, 55203: 240, 33701: 241, 18341: 242, 39335: 243, 6056: 244, 15268: 245, 32170: 246, 61356: 247, 431: 248, 8113: 249, 33201: 250, 34740: 251, 7093: 252, 54199: 253, 28601: 254, 25018: 255, 33211: 256, 25020: 257, 41916: 258, 30654: 259, 11709: 260, 57280: 261, 12223: 262, 53186: 263, 10691: 264, 26565: 265, 34758: 266, 9670: 267, 7114: 268, 34763: 269, 3530: 270, 14286: 271, 51153: 272, 22484: 273, 16341: 274, 54235: 275, 41953: 276, 32254: 277, 56808: 278, 29163: 279, 4589: 280, 46062: 281, 63471: 282, 53233: 283, 21490: 284, 18423: 285, 23544: 286, 65017: 287, 6651: 288, 33790: 289, 23039: 290}\n","KerasTensor(type_spec=TensorSpec(shape=(None, 71), dtype=tf.float32, name=None), name='lambda_3/concat:0', description=\"created by layer 'lambda_3'\")\n","Epoch 1/50\n","23/23 [==============================] - 8s 102ms/step - loss: 3.2189 - acc: 0.7135 - mae: 2.9938 - auc: 0.8149\n","Epoch 2/50\n","23/23 [==============================] - 2s 98ms/step - loss: 2.3464 - acc: 0.8428 - mae: 2.4919 - auc: 0.8919\n","Epoch 3/50\n","23/23 [==============================] - 2s 102ms/step - loss: 1.9370 - acc: 0.8734 - mae: 2.4274 - auc: 0.9137\n","Epoch 4/50\n","23/23 [==============================] - 2s 99ms/step - loss: 1.6301 - acc: 0.8804 - mae: 2.8597 - auc: 0.9121\n","Epoch 5/50\n","23/23 [==============================] - 3s 116ms/step - loss: 1.3798 - acc: 0.8901 - mae: 2.8461 - auc: 0.9174\n","Epoch 6/50\n","23/23 [==============================] - 3s 123ms/step - loss: 1.1789 - acc: 0.8943 - mae: 2.8377 - auc: 0.9280\n","Epoch 7/50\n","23/23 [==============================] - 2s 100ms/step - loss: 1.0124 - acc: 0.9040 - mae: 2.9474 - auc: 0.9342\n","Epoch 8/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.8793 - acc: 0.8971 - mae: 3.2361 - auc: 0.9285\n","Epoch 9/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.7671 - acc: 0.8999 - mae: 3.0735 - auc: 0.9333\n","Epoch 10/50\n","23/23 [==============================] - 2s 97ms/step - loss: 0.6776 - acc: 0.9096 - mae: 3.1217 - auc: 0.9376\n","Epoch 11/50\n","23/23 [==============================] - 3s 117ms/step - loss: 0.6014 - acc: 0.9082 - mae: 3.1780 - auc: 0.9403\n","Epoch 12/50\n","23/23 [==============================] - 3s 125ms/step - loss: 0.5444 - acc: 0.9026 - mae: 3.4479 - auc: 0.9341\n","Epoch 13/50\n","23/23 [==============================] - 2s 98ms/step - loss: 0.4924 - acc: 0.9054 - mae: 3.3112 - auc: 0.9396\n","Epoch 14/50\n","23/23 [==============================] - 2s 97ms/step - loss: 0.4503 - acc: 0.9096 - mae: 3.4952 - auc: 0.9294\n","Epoch 15/50\n","23/23 [==============================] - 2s 98ms/step - loss: 0.4197 - acc: 0.9166 - mae: 3.4515 - auc: 0.9419\n","Epoch 16/50\n","23/23 [==============================] - 2s 98ms/step - loss: 0.3910 - acc: 0.9082 - mae: 3.3069 - auc: 0.9338\n","Epoch 17/50\n","23/23 [==============================] - 3s 115ms/step - loss: 0.3641 - acc: 0.9096 - mae: 3.5889 - auc: 0.9382\n","Epoch 18/50\n","23/23 [==============================] - 3s 124ms/step - loss: 0.3518 - acc: 0.9096 - mae: 3.7657 - auc: 0.9362\n","Epoch 19/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.3311 - acc: 0.9138 - mae: 3.5679 - auc: 0.9416\n","Epoch 20/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.3168 - acc: 0.9138 - mae: 3.6340 - auc: 0.9367\n","Epoch 21/50\n","23/23 [==============================] - 2s 98ms/step - loss: 0.3051 - acc: 0.9082 - mae: 3.5346 - auc: 0.9411\n","Epoch 22/50\n","23/23 [==============================] - 2s 97ms/step - loss: 0.2937 - acc: 0.9179 - mae: 3.4584 - auc: 0.9488\n","Epoch 23/50\n","23/23 [==============================] - 3s 120ms/step - loss: 0.2870 - acc: 0.9207 - mae: 3.4892 - auc: 0.9381\n","Epoch 24/50\n","23/23 [==============================] - 3s 124ms/step - loss: 0.2767 - acc: 0.9193 - mae: 3.4383 - auc: 0.9484\n","Epoch 25/50\n","23/23 [==============================] - 2s 98ms/step - loss: 0.2720 - acc: 0.9179 - mae: 3.5685 - auc: 0.9363\n","Epoch 26/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.2732 - acc: 0.9026 - mae: 3.7191 - auc: 0.9347\n","Epoch 27/50\n","23/23 [==============================] - 2s 98ms/step - loss: 0.2649 - acc: 0.9166 - mae: 3.6279 - auc: 0.9406\n","Epoch 28/50\n","23/23 [==============================] - 2s 97ms/step - loss: 0.2605 - acc: 0.9193 - mae: 3.6274 - auc: 0.9397\n","Epoch 29/50\n","23/23 [==============================] - 3s 122ms/step - loss: 0.2552 - acc: 0.9082 - mae: 3.7461 - auc: 0.9445\n","Epoch 30/50\n","23/23 [==============================] - 3s 118ms/step - loss: 0.2578 - acc: 0.9054 - mae: 3.5917 - auc: 0.9423\n","Epoch 31/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.2508 - acc: 0.9166 - mae: 3.6222 - auc: 0.9426\n","Epoch 32/50\n","23/23 [==============================] - 2s 97ms/step - loss: 0.2491 - acc: 0.9152 - mae: 3.9020 - auc: 0.9372\n","Epoch 33/50\n","23/23 [==============================] - 2s 96ms/step - loss: 0.2499 - acc: 0.9138 - mae: 3.6402 - auc: 0.9462\n","Epoch 34/50\n","23/23 [==============================] - 2s 98ms/step - loss: 0.2461 - acc: 0.9124 - mae: 3.6251 - auc: 0.9370\n","Epoch 35/50\n","23/23 [==============================] - 3s 119ms/step - loss: 0.2416 - acc: 0.9096 - mae: 3.8658 - auc: 0.9385\n","Epoch 36/50\n","23/23 [==============================] - 3s 122ms/step - loss: 0.2438 - acc: 0.9124 - mae: 3.4446 - auc: 0.9466\n","Epoch 37/50\n","23/23 [==============================] - 2s 95ms/step - loss: 0.2504 - acc: 0.9152 - mae: 3.8962 - auc: 0.9363\n","Epoch 38/50\n","23/23 [==============================] - 2s 96ms/step - loss: 0.2446 - acc: 0.9179 - mae: 3.7448 - auc: 0.9363\n","Epoch 39/50\n","23/23 [==============================] - 2s 95ms/step - loss: 0.2379 - acc: 0.9138 - mae: 3.5945 - auc: 0.9451\n","Epoch 40/50\n","23/23 [==============================] - 2s 98ms/step - loss: 0.2360 - acc: 0.9138 - mae: 3.6592 - auc: 0.9387\n","Epoch 41/50\n","23/23 [==============================] - 3s 114ms/step - loss: 0.2367 - acc: 0.9179 - mae: 3.7941 - auc: 0.9377\n","Epoch 42/50\n","23/23 [==============================] - 3s 122ms/step - loss: 0.2395 - acc: 0.9068 - mae: 3.6530 - auc: 0.9394\n","Epoch 43/50\n","23/23 [==============================] - 2s 97ms/step - loss: 0.2339 - acc: 0.9124 - mae: 3.7234 - auc: 0.9448\n","Epoch 44/50\n","23/23 [==============================] - 2s 98ms/step - loss: 0.2319 - acc: 0.9152 - mae: 3.8697 - auc: 0.9450\n","Epoch 45/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.2426 - acc: 0.9138 - mae: 3.6346 - auc: 0.9313\n","Epoch 46/50\n","23/23 [==============================] - 2s 98ms/step - loss: 0.2324 - acc: 0.9124 - mae: 3.5671 - auc: 0.9423\n","Epoch 47/50\n","23/23 [==============================] - 3s 114ms/step - loss: 0.2313 - acc: 0.9193 - mae: 3.5147 - auc: 0.9428\n","Epoch 48/50\n","23/23 [==============================] - 3s 127ms/step - loss: 0.2372 - acc: 0.9110 - mae: 3.7686 - auc: 0.9368\n","Epoch 49/50\n","23/23 [==============================] - 2s 97ms/step - loss: 0.2344 - acc: 0.9082 - mae: 3.5757 - auc: 0.9436\n","Epoch 50/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.2396 - acc: 0.9110 - mae: 3.8233 - auc: 0.9366\n","Logging Info - Training time: 00:02:27\n","23/23 [==============================] - 1s 3ms/step\n","6/6 [==============================] - 0s 5ms/step\n","\n","Logging Info - Fold 4 Result : {'AUC': 0.9101123595505618, 'ACC': 0.8156424581005587, 'F1 Score': 0.8070175438596492, 'AUPR': 0.9143881304234833}\n","\n","Logging Info - Fold 5 >>>>>>>>>>>>>>\n","\n","test_indices: [1, 2, 5, 10, 27, 28, 31, 35, 48, 51, 53, 54, 56, 63, 70, 75, 77, 80, 83, 84, 86, 91, 100, 107, 109, 110, 113, 121, 127, 128, 143, 163, 169, 172, 180, 185, 190, 193, 196, 201, 210, 215, 222, 223, 225, 228, 236, 245, 252, 260, 263, 278, 282, 287, 288, 292, 294, 299, 301, 316, 317, 318, 319, 327, 335, 337, 342, 349, 351, 363, 365, 372, 378, 388, 390, 395, 396, 409, 413, 414, 415, 419, 430, 432, 445, 448, 449, 450, 451, 456, 460, 461, 462, 464, 470, 477, 481, 487, 495, 496, 500, 506, 507, 518, 520, 529, 530, 532, 535, 539, 550, 553, 554, 555, 559, 571, 579, 582, 586, 589, 590, 594, 597, 598, 600, 601, 602, 604, 607, 612, 620, 623, 629, 646, 649, 650, 651, 655, 657, 663, 667, 669, 670, 671, 675, 680, 681, 682, 683, 695, 698, 700, 703, 704, 713, 714, 715, 723, 727, 731, 750, 752, 755, 757, 758, 759, 774, 789, 797, 800, 822, 834, 837, 841, 843, 848, 852, 862, 866, 876, 878, 883]\n","train_indices: [0, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 81, 82, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 108, 111, 112, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 170, 171, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 194, 195, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 216, 217, 218, 219, 220, 221, 224, 226, 227, 229, 230, 231, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 248, 249, 250, 251, 253, 254, 255, 256, 257, 258, 259, 261, 262, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 279, 280, 281, 283, 284, 285, 286, 289, 290, 291, 293, 295, 296, 297, 298, 300, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 336, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 350, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 366, 367, 368, 369, 370, 371, 373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 386, 387, 389, 391, 392, 393, 394, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 410, 411, 412, 416, 417, 418, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 446, 447, 452, 453, 454, 455, 457, 458, 459, 463, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 476, 478, 479, 480, 482, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 497, 498, 499, 501, 502, 503, 504, 505, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 519, 521, 522, 523, 524, 525, 526, 527, 528, 531, 533, 534, 536, 537, 538, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 552, 556, 557, 558, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 572, 573, 574, 575, 576, 577, 578, 580, 581, 583, 584, 585, 587, 588, 591, 592, 593, 595, 596, 599, 603, 605, 606, 608, 609, 610, 611, 613, 614, 615, 616, 617, 618, 619, 621, 622, 624, 625, 626, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 647, 648, 652, 653, 654, 656, 658, 659, 660, 661, 662, 664, 665, 666, 668, 672, 673, 674, 676, 677, 678, 679, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 696, 697, 699, 701, 702, 705, 706, 707, 708, 709, 710, 711, 712, 716, 717, 718, 719, 720, 721, 722, 724, 725, 726, 728, 729, 730, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 751, 753, 754, 756, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 790, 791, 792, 793, 794, 795, 796, 798, 799, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 835, 836, 838, 839, 840, 842, 844, 845, 846, 847, 849, 850, 851, 853, 854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 865, 867, 868, 869, 870, 871, 872, 873, 874, 875, 877, 879, 880, 881, 882, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897]\n","\n","first_term2id= {64642: 0, 1667: 1, 50436: 2, 48777: 3, 10506: 4, 33293: 5, 654: 6, 30861: 7, 11153: 8, 64149: 9, 61336: 10, 63129: 11, 13213: 12, 55164: 13, 40873: 14, 34347: 15, 50863: 16, 59444: 17, 22068: 18, 3127: 19, 44991: 20, 66623: 21, 4928: 22, 25026: 23, 7877: 24, 200: 25, 44112: 26, 31069: 27, 54370: 28, 20066: 29, 43621: 30, 66282: 31, 43372: 32, 28016: 33, 12403: 34, 45301: 35, 37496: 36, 9724: 37, 13565: 38} second_term2id= {24065: 0, 19458: 1, 40449: 2, 30212: 3, 12808: 4, 50698: 5, 20492: 6, 46605: 7, 5135: 8, 37392: 9, 42514: 10, 20153: 11, 12824: 12, 37400: 13, 8218: 14, 1049: 15, 30750: 16, 48672: 17, 56353: 18, 52770: 19, 31268: 20, 46117: 21, 10276: 22, 59432: 23, 57903: 24, 2097: 25, 24627: 26, 29241: 27, 50234: 28, 19514: 29, 9788: 30, 14909: 31, 8766: 32, 60987: 33, 64571: 34, 35905: 35, 27202: 36, 26183: 37, 4683: 38, 44108: 39, 33867: 40, 7246: 41, 42577: 42, 61523: 43, 3157: 44, 12374: 45, 3669: 46, 5718: 47, 6745: 48, 64598: 49, 51285: 50, 25176: 51, 35933: 52, 54366: 53, 56416: 54, 35937: 55, 59489: 56, 4707: 57, 4193: 58, 37477: 59, 29281: 60, 35941: 61, 6245: 62, 55403: 63, 18028: 64, 57454: 65, 63599: 66, 54894: 67, 29807: 68, 42610: 69, 62073: 70, 10873: 71, 3195: 72, 46716: 73, 45697: 74, 4739: 75, 47235: 76, 11907: 77, 64132: 78, 41608: 79, 25737: 80, 29322: 81, 65679: 82, 41105: 83, 35986: 84, 38545: 85, 54932: 86, 148: 87, 20627: 88, 45720: 89, 32921: 90, 4251: 91, 53920: 92, 58532: 93, 26788: 94, 15014: 95, 60583: 96, 15528: 97, 46252: 98, 19630: 99, 45746: 100, 179: 101, 47287: 102, 59577: 103, 60601: 104, 43707: 105, 46268: 106, 36028: 107, 15547: 108, 12991: 109, 59584: 110, 52416: 111, 23739: 112, 35015: 113, 13000: 114, 57545: 115, 27335: 116, 25804: 117, 1743: 118, 5846: 119, 45273: 120, 9949: 121, 5344: 122, 63715: 123, 19172: 124, 38632: 125, 1773: 126, 29422: 127, 57582: 128, 48368: 129, 61681: 130, 20724: 131, 35575: 132, 32506: 133, 30970: 134, 16122: 135, 12541: 136, 25341: 137, 56575: 138, 34048: 139, 11010: 140, 7427: 141, 15620: 142, 45317: 143, 35590: 144, 28933: 145, 47880: 146, 34574: 147, 61711: 148, 23823: 149, 57617: 150, 20754: 151, 23314: 152, 5396: 153, 58642: 154, 65813: 155, 28944: 156, 23832: 157, 65819: 158, 44316: 159, 27935: 160, 8480: 161, 25376: 162, 19744: 163, 6432: 164, 55588: 165, 51493: 166, 1823: 167, 40740: 168, 14120: 169, 8488: 170, 56106: 171, 12583: 172, 32044: 173, 53038: 174, 64304: 175, 62257: 176, 34610: 177, 5427: 178, 51508: 179, 6454: 180, 15670: 181, 39226: 182, 63804: 183, 10559: 184, 60226: 185, 22850: 186, 16707: 187, 10565: 188, 35142: 189, 49992: 190, 13641: 191, 18765: 192, 6993: 193, 54098: 194, 7506: 195, 59219: 196, 7507: 197, 11601: 198, 32087: 199, 25943: 200, 7516: 201, 65885: 202, 32606: 203, 40800: 204, 31584: 205, 57696: 206, 60261: 207, 30566: 208, 39272: 209, 50024: 210, 63336: 211, 52077: 212, 878: 213, 13682: 214, 26995: 215, 25460: 216, 27509: 217, 19319: 218, 32631: 219, 4986: 220, 32635: 221, 3965: 222, 40832: 223, 59776: 224, 32642: 225, 5508: 226, 57221: 227, 20358: 228, 7051: 229, 48011: 230, 56210: 231, 19860: 232, 56727: 233, 53656: 234, 926: 235, 49054: 236, 29598: 237, 48031: 238, 53155: 239, 55203: 240, 33701: 241, 18341: 242, 39335: 243, 6056: 244, 15268: 245, 32170: 246, 61356: 247, 431: 248, 8113: 249, 33201: 250, 34740: 251, 7093: 252, 54199: 253, 28601: 254, 25018: 255, 33211: 256, 25020: 257, 41916: 258, 30654: 259, 11709: 260, 57280: 261, 12223: 262, 53186: 263, 10691: 264, 26565: 265, 34758: 266, 9670: 267, 7114: 268, 34763: 269, 3530: 270, 14286: 271, 51153: 272, 22484: 273, 16341: 274, 54235: 275, 41953: 276, 32254: 277, 56808: 278, 29163: 279, 4589: 280, 46062: 281, 63471: 282, 53233: 283, 21490: 284, 18423: 285, 23544: 286, 65017: 287, 6651: 288, 33790: 289, 23039: 290}\n","KerasTensor(type_spec=TensorSpec(shape=(None, 71), dtype=tf.float32, name=None), name='lambda_3/concat:0', description=\"created by layer 'lambda_3'\")\n","Epoch 1/50\n","23/23 [==============================] - 6s 105ms/step - loss: 3.2084 - acc: 0.6885 - mae: 2.8747 - auc: 0.7961\n","Epoch 2/50\n","23/23 [==============================] - 3s 137ms/step - loss: 2.3214 - acc: 0.8338 - mae: 2.7117 - auc: 0.9041\n","Epoch 3/50\n","23/23 [==============================] - 4s 165ms/step - loss: 1.9147 - acc: 0.8743 - mae: 2.8256 - auc: 0.9114\n","Epoch 4/50\n","23/23 [==============================] - 3s 120ms/step - loss: 1.6067 - acc: 0.8953 - mae: 2.7617 - auc: 0.9282\n","Epoch 5/50\n","23/23 [==============================] - 2s 105ms/step - loss: 1.3641 - acc: 0.8869 - mae: 3.0708 - auc: 0.9280\n","Epoch 6/50\n","23/23 [==============================] - 2s 107ms/step - loss: 1.1641 - acc: 0.8911 - mae: 3.1743 - auc: 0.9239\n","Epoch 7/50\n","23/23 [==============================] - 2s 104ms/step - loss: 1.0032 - acc: 0.8953 - mae: 3.4583 - auc: 0.9192\n","Epoch 8/50\n","23/23 [==============================] - 3s 128ms/step - loss: 0.8717 - acc: 0.9008 - mae: 3.2670 - auc: 0.9392\n","Epoch 9/50\n","23/23 [==============================] - 3s 122ms/step - loss: 0.7677 - acc: 0.8994 - mae: 3.3260 - auc: 0.9317\n","Epoch 10/50\n","23/23 [==============================] - 2s 103ms/step - loss: 0.6799 - acc: 0.8980 - mae: 3.6134 - auc: 0.9305\n","Epoch 11/50\n","23/23 [==============================] - 2s 107ms/step - loss: 0.6081 - acc: 0.9092 - mae: 3.4933 - auc: 0.9346\n","Epoch 12/50\n","23/23 [==============================] - 2s 102ms/step - loss: 0.5457 - acc: 0.9064 - mae: 3.5466 - auc: 0.9368\n","Epoch 13/50\n","23/23 [==============================] - 2s 105ms/step - loss: 0.4938 - acc: 0.9092 - mae: 3.3318 - auc: 0.9441\n","Epoch 14/50\n","23/23 [==============================] - 3s 131ms/step - loss: 0.4659 - acc: 0.9078 - mae: 3.7570 - auc: 0.9340\n","Epoch 15/50\n","23/23 [==============================] - 3s 115ms/step - loss: 0.4261 - acc: 0.9008 - mae: 3.6888 - auc: 0.9393\n","Epoch 16/50\n","23/23 [==============================] - 2s 106ms/step - loss: 0.3959 - acc: 0.9050 - mae: 3.5516 - auc: 0.9381\n","Epoch 17/50\n","23/23 [==============================] - 2s 102ms/step - loss: 0.3779 - acc: 0.9106 - mae: 3.5037 - auc: 0.9405\n","Epoch 18/50\n","23/23 [==============================] - 2s 102ms/step - loss: 0.3552 - acc: 0.9120 - mae: 3.5555 - auc: 0.9371\n","Epoch 19/50\n","23/23 [==============================] - 3s 118ms/step - loss: 0.3433 - acc: 0.9120 - mae: 3.6338 - auc: 0.9363\n","Epoch 20/50\n","23/23 [==============================] - 3s 136ms/step - loss: 0.3259 - acc: 0.9106 - mae: 3.7291 - auc: 0.9337\n","Epoch 21/50\n","23/23 [==============================] - 2s 104ms/step - loss: 0.3217 - acc: 0.9120 - mae: 3.7220 - auc: 0.9334\n","Epoch 22/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.3200 - acc: 0.9106 - mae: 4.1044 - auc: 0.9302\n","Epoch 23/50\n","23/23 [==============================] - 2s 102ms/step - loss: 0.3015 - acc: 0.9064 - mae: 3.6438 - auc: 0.9421\n","Epoch 24/50\n","23/23 [==============================] - 2s 103ms/step - loss: 0.2911 - acc: 0.9134 - mae: 3.6155 - auc: 0.9348\n","Epoch 25/50\n","23/23 [==============================] - 3s 134ms/step - loss: 0.2867 - acc: 0.9078 - mae: 3.6982 - auc: 0.9375\n","Epoch 26/50\n","23/23 [==============================] - 3s 121ms/step - loss: 0.2806 - acc: 0.9162 - mae: 3.5343 - auc: 0.9399\n","Epoch 27/50\n","23/23 [==============================] - 2s 102ms/step - loss: 0.2760 - acc: 0.9120 - mae: 3.7134 - auc: 0.9344\n","Epoch 28/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.2720 - acc: 0.9106 - mae: 3.6639 - auc: 0.9390\n","Epoch 29/50\n","23/23 [==============================] - 2s 103ms/step - loss: 0.2723 - acc: 0.9148 - mae: 3.5905 - auc: 0.9338\n","Epoch 30/50\n","23/23 [==============================] - 2s 104ms/step - loss: 0.2824 - acc: 0.9092 - mae: 3.9059 - auc: 0.9270\n","Epoch 31/50\n","23/23 [==============================] - 3s 131ms/step - loss: 0.2597 - acc: 0.9036 - mae: 3.9070 - auc: 0.9342\n","Epoch 32/50\n","23/23 [==============================] - 3s 112ms/step - loss: 0.2687 - acc: 0.9148 - mae: 3.7342 - auc: 0.9294\n","Epoch 33/50\n","23/23 [==============================] - 2s 101ms/step - loss: 0.2610 - acc: 0.9106 - mae: 3.4590 - auc: 0.9413\n","Epoch 34/50\n","23/23 [==============================] - 2s 102ms/step - loss: 0.2577 - acc: 0.9134 - mae: 3.6142 - auc: 0.9410\n","Epoch 35/50\n","23/23 [==============================] - 2s 103ms/step - loss: 0.2566 - acc: 0.9176 - mae: 3.6769 - auc: 0.9342\n","Epoch 36/50\n","23/23 [==============================] - 3s 118ms/step - loss: 0.2544 - acc: 0.9148 - mae: 3.8451 - auc: 0.9334\n","Epoch 37/50\n","23/23 [==============================] - 3s 136ms/step - loss: 0.2554 - acc: 0.9148 - mae: 3.6700 - auc: 0.9368\n","Epoch 38/50\n","23/23 [==============================] - 2s 105ms/step - loss: 0.2510 - acc: 0.9134 - mae: 3.5980 - auc: 0.9404\n","Epoch 39/50\n","23/23 [==============================] - 2s 102ms/step - loss: 0.2519 - acc: 0.9106 - mae: 3.9316 - auc: 0.9306\n","Epoch 40/50\n","23/23 [==============================] - 2s 105ms/step - loss: 0.2523 - acc: 0.9092 - mae: 3.6345 - auc: 0.9366\n","Epoch 41/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.2522 - acc: 0.9050 - mae: 3.6703 - auc: 0.9337\n","Epoch 42/50\n","23/23 [==============================] - 3s 120ms/step - loss: 0.2484 - acc: 0.9050 - mae: 3.7322 - auc: 0.9379\n","Epoch 43/50\n","23/23 [==============================] - 3s 128ms/step - loss: 0.2456 - acc: 0.9120 - mae: 3.6122 - auc: 0.9392\n","Epoch 44/50\n","23/23 [==============================] - 2s 99ms/step - loss: 0.2502 - acc: 0.9092 - mae: 3.5411 - auc: 0.9364\n","Epoch 45/50\n","23/23 [==============================] - 2s 102ms/step - loss: 0.2463 - acc: 0.9162 - mae: 3.5756 - auc: 0.9373\n","Epoch 46/50\n","23/23 [==============================] - 2s 103ms/step - loss: 0.2510 - acc: 0.9134 - mae: 3.4633 - auc: 0.9384\n","Epoch 47/50\n","23/23 [==============================] - 2s 101ms/step - loss: 0.2625 - acc: 0.8966 - mae: 4.0569 - auc: 0.9233\n","Epoch 48/50\n","23/23 [==============================] - 3s 129ms/step - loss: 0.2427 - acc: 0.9162 - mae: 3.7634 - auc: 0.9331\n","Epoch 49/50\n","23/23 [==============================] - 3s 120ms/step - loss: 0.2424 - acc: 0.9204 - mae: 3.6792 - auc: 0.9342\n","Epoch 50/50\n","23/23 [==============================] - 2s 100ms/step - loss: 0.2486 - acc: 0.9134 - mae: 3.7642 - auc: 0.9431\n","Logging Info - Training time: 00:02:25\n","23/23 [==============================] - 0s 3ms/step\n","6/6 [==============================] - 0s 5ms/step\n","\n","Logging Info - Fold 5 Result : {'AUC': 0.9166666666666666, 'ACC': 0.8076923076923077, 'F1 Score': 0.7712418300653594, 'AUPR': 0.9155341812340259}\n","\n","Logging Info - 5 fold result: avg_auc: 0.9064892741699321, avg_acc: 0.8140524280189085, avg_f1: 0.7992394616721754, avg_aupr: 0.9131786650231039\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["<base.evaluation.Result at 0x787532dcd510>"]},"metadata":{},"execution_count":27}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4,"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}